{
  "timestamp": "20250916_174757",
  "run_date": "2025-09-16T17:47:57.967109",
  "config": {
    "environment": "development",
    "max_stories": 20,
    "tts_voice": "en-US-Neural2-D"
  },
  "stories": [
    {
      "id": 45270965,
      "title": "Global Peace Index 2025",
      "url": "https://www.visionofhumanity.org/maps/",
      "score": 35,
      "by": "teleforce",
      "time": 1758076629,
      "descendants": 28,
      "type": "story",
      "created_at": "2025-09-16T16:37:09"
    },
    {
      "id": 45270108,
      "title": "Apple releases iOS 15.8.5 security update for 10-year old iPhone 6s",
      "url": "https://support.apple.com/en-us/125142",
      "score": 216,
      "by": "jerlam",
      "time": 1758069242,
      "descendants": 58,
      "type": "story",
      "created_at": "2025-09-16T14:34:02"
    },
    {
      "id": 45262835,
      "title": "Things you can do with a Software Defined Radio (2024)",
      "url": "https://blinry.org/50-things-with-sdr/",
      "score": 646,
      "by": "mihau",
      "time": 1758033319,
      "descendants": 116,
      "type": "story",
      "created_at": "2025-09-16T04:35:19"
    },
    {
      "id": 45266039,
      "title": "How to make the Framework Desktop run even quieter",
      "url": "https://noctua.at/en/how-to-make-the-framework-desktop-run-even-quieter",
      "score": 215,
      "by": "lwhsiao",
      "time": 1758047601,
      "descendants": 65,
      "type": "story",
      "created_at": "2025-09-16T08:33:21"
    },
    {
      "id": 45270482,
      "title": "Irssi: IRC Client in a Docker Image",
      "url": "https://hub.docker.com/_/irssi",
      "score": 17,
      "by": "razodactyl",
      "time": 1758072401,
      "descendants": 19,
      "type": "story",
      "created_at": "2025-09-16T15:26:41"
    },
    {
      "id": 45265745,
      "title": "Denmark close to wiping out cancer-causing HPV strains after vaccine roll-out",
      "url": "https://www.gavi.org/vaccineswork/denmark-close-wiping-out-leading-cancer-causing-hpv-strains-after-vaccine-roll-out",
      "score": 569,
      "by": "slu",
      "time": 1758046349,
      "descendants": 228,
      "type": "story",
      "created_at": "2025-09-16T08:12:29"
    },
    {
      "id": 45268269,
      "title": "Doom crash after 2.5 years of real-world runtime confirmed on real hardware",
      "url": "https://lenowo.org/viewtopic.php?t=31",
      "score": 100,
      "by": "minki_the_avali",
      "time": 1758057863,
      "descendants": 38,
      "type": "story",
      "created_at": "2025-09-16T11:24:23"
    },
    {
      "id": 45248558,
      "title": "A dumb introduction to z3",
      "url": "https://asibahi.github.io/thoughts/a-gentle-introduction-to-z3/",
      "score": 140,
      "by": "kfl",
      "time": 1757936805,
      "descendants": 14,
      "type": "story",
      "created_at": "2025-09-15T01:46:45"
    },
    {
      "id": 45232940,
      "title": "CubeSats are fascinating learning tools for space",
      "url": "https://www.jeffgeerling.com/blog/2025/cubesats-are-fascinating-learning-tools-space",
      "score": 23,
      "by": "calcifer",
      "time": 1757777865,
      "descendants": 1,
      "type": "story",
      "created_at": "2025-09-13T05:37:45"
    },
    {
      "id": 45270676,
      "title": "Slow Social Media",
      "url": "https://herman.bearblog.dev/slow-social-media/",
      "score": 15,
      "by": "rishikeshs",
      "time": 1758074278,
      "descendants": 6,
      "type": "story",
      "created_at": "2025-09-16T15:57:58"
    },
    {
      "id": 45260741,
      "title": "Shai-Hulud malware attack: Tinycolor and over 40 NPM packages compromised",
      "url": "https://www.stepsecurity.io/blog/ctrl-tinycolor-and-40-npm-packages-compromised",
      "score": 934,
      "by": "jamesberthoty",
      "time": 1758021723,
      "descendants": 726,
      "type": "story",
      "created_at": "2025-09-16T01:22:03"
    },
    {
      "id": 45264562,
      "title": "Waymo has received our pilot permit allowing for commercial operations at SFO",
      "url": "https://waymo.com/blog/#short-all-systems-go-at-sfo-waymo-has-received-our-pilot-permit",
      "score": 591,
      "by": "ChrisArchitect",
      "time": 1758040688,
      "descendants": 573,
      "type": "story",
      "created_at": "2025-09-16T06:38:08"
    },
    {
      "id": 45245050,
      "title": "I built my own phone because innovation is sad rn [video]",
      "url": "https://www.youtube.com/watch?v=qy_9w_c2ub0",
      "score": 198,
      "by": "Timothee",
      "time": 1757898731,
      "descendants": 38,
      "type": "story",
      "created_at": "2025-09-14T15:12:11"
    },
    {
      "id": 45266947,
      "title": "In Defense of C++",
      "url": "https://dayvster.com/blog/in-defense-of-cpp/",
      "score": 91,
      "by": "todsacerdoti",
      "time": 1758051634,
      "descendants": 140,
      "type": "story",
      "created_at": "2025-09-16T09:40:34"
    },
    {
      "id": 45235167,
      "title": "Wait4X allows you to wait for a port or a service to enter the requested state",
      "url": "https://github.com/wait4x/wait4x",
      "score": 21,
      "by": "atkrad",
      "time": 1757796358,
      "descendants": 5,
      "type": "story",
      "created_at": "2025-09-13T10:45:58"
    },
    {
      "id": 45270087,
      "title": "AMDVLK (AMD Open Source Driver For Vulkan) project is discontinued",
      "url": "https://github.com/GPUOpen-Drivers/AMDVLK/discussions/416",
      "score": 16,
      "by": "haunter",
      "time": 1758069064,
      "descendants": 3,
      "type": "story",
      "created_at": "2025-09-16T14:31:04"
    },
    {
      "id": 45264867,
      "title": "Launch HN: Rowboat (YC S24) – Open-source IDE for multi-agent systems",
      "url": "https://github.com/rowboatlabs/rowboat",
      "score": 51,
      "by": "segmenta",
      "time": 1758042076,
      "descendants": 22,
      "type": "story",
      "created_at": "2025-09-16T07:01:16"
    },
    {
      "id": 45232426,
      "title": "How Container Filesystem Works: Building a Docker-Like Container from Scratch",
      "url": "https://labs.iximiuz.com/tutorials/container-filesystem-from-scratch",
      "score": 118,
      "by": "lgunsch",
      "time": 1757774272,
      "descendants": 22,
      "type": "story",
      "created_at": "2025-09-13T04:37:52"
    },
    {
      "id": 45229322,
      "title": "Mystery in the Moon",
      "url": "https://engelsbergideas.com/reviews/mystery-in-the-moon/",
      "score": 4,
      "by": "benbreen",
      "time": 1757738018,
      "descendants": 0,
      "type": "story",
      "created_at": "2025-09-12T18:33:38"
    },
    {
      "id": 45270981,
      "title": "Show HN: A PSX/DOS style 3D game written in Rust with a custom software renderer",
      "url": "https://totenarctanz.itch.io/a-scavenging-trip",
      "score": 6,
      "by": "mvx64",
      "time": 1758076759,
      "descendants": 0,
      "type": "story",
      "created_at": "2025-09-16T16:39:19"
    }
  ],
  "scraped_content": [
    {
      "url": "https://www.visionofhumanity.org/maps/",
      "title": "Global Peace Index 2025",
      "content": "The Global Peace Index 2024 reveals that the world is at a crossroads. Without concerted effort, there is a risk of a surge in major conflicts. There are currently 56 conflicts, the most since World War II. They have become more international with 92 countries involved in conflicts outside their borders, the most since the GPI’s inception. The rising number of minor conflicts increases the likelihood of more major conflicts in the future. For example, in 2019, Ethiopia, Ukraine, and Gaza were all identified as minor conflicts.\n• 97 countries deteriorated in peacefulness, more than any year since the inception of the Global Peace Index in 2008.\n• Conflicts in Gaza and Ukraine were the primary drivers of the global fall in peacefulness, as battle deaths reached 162,000 in 2023.\n• 92 countries are currently involved in conflicts beyond their borders, more than at any time since the inception of the GPI.\n• First of its kind military scoring system suggests that US military capabilities are up to three times higher than China.\n• The global economic impact of violence increased to $19.1 trillion in 2023, representing 13.5% of global GDP. Exposure to conflict poses a significant supply chain risk for governments and businesses.\n• Militarisation recorded its largest yearly deterioration since the inception of the GPI, with 108 countries becoming more militarised.\n• 110 million people are either refugees or internally displaced due to violent conflict, with 16 countries now hosting more than half a million refugees.\n• North America saw the largest regional deterioration, driven by increases in violent crime and fear of violence.\n• Iceland, Ireland, Austria, New Zealand, and Singapore are the top 5 most peaceful countries in the world in 2024.\n\nLast year recorded 162,000 conflict related deaths. This was the second highest toll in the past 30 years, with the conflicts in Ukraine and Gaza accounting for nearly three-quarters of deaths. Ukraine represented more than half, recording 83,000 conflict deaths, with estimates of at least 33,000 for Palestine up to April 2024. In the first four months of 2024, conflict related deaths globally amounted to 47,000. If the same rate continues for the rest of this year, it would be the highest number of conflict deaths since the Rwandan genocide in 1994.\n\nRead more: Highest number of countries engaged in conflict since World War II",
      "author": null,
      "published_date": null,
      "meta_description": "Global Peace Index (GPI) presents most comprehensive data-driven analysis on trends in peace. Most & least peaceful countries in the world. View Map.",
      "word_count": 391,
      "scraping_method": "goose3"
    },
    {
      "url": "https://support.apple.com/en-us/125142",
      "title": "Apple releases iOS 15.8.5 security update for 10-year old iPhone 6s",
      "content": "About the security content of iOS 15.8.5 and iPadOS 15.8.5\nThis document describes the security content of iOS 15.8.5 and iPadOS 15.8.5.\nAbout Apple security updates\nFor our customers' protection, Apple doesn't disclose, discuss, or confirm security issues until an investigation has occurred and patches or releases are available. Recent releases are listed on the Apple security releases page.\nApple security documents reference vulnerabilities by CVE-ID when possible.\nFor more information about security, see the Apple Product Security page.\niOS 15.8.5 and iPadOS 15.8.5\nReleased September 15, 2025\nImageIO\nAvailable for: iPhone 6s (all models), iPhone 7 (all models), iPhone SE (1st generation), iPad Air 2, iPad mini (4th generation), and iPod touch (7th generation)\nImpact: Processing a malicious image file may result in memory corruption. Apple is aware of a report that this issue may have been exploited in an extremely sophisticated attack against specific targeted individuals.\nDescription: An out-of-bounds write issue was addressed with improved bounds checking.\nCVE-2025-43300: Apple\nInformation about products not manufactured by Apple, or independent websites not controlled or tested by Apple, is provided without recommendation or endorsement. Apple assumes no responsibility with regard to the selection, performance, or use of third-party websites or products. Apple makes no representations regarding third-party website accuracy or reliability. Contact the vendor for additional information.\nPublished Date: September 15, 2025",
      "author": null,
      "published_date": null,
      "meta_description": "This document describes the security content of iOS 15.8.5 and iPadOS 15.8.5.",
      "word_count": 221,
      "scraping_method": "beautifulsoup"
    },
    {
      "url": "https://blinry.org/50-things-with-sdr/",
      "title": "Things you can do with a Software Defined Radio (2024)",
      "content": "Fifty Things you can do with a Software Defined Radio 📻\n\nLast week, I went on an adventure through the electromagnetic spectrum!\n\nIt’s like an invisible world that always surrounds us, and allows us to do many amazing things: It’s how radio and TV are transmitted, it’s how we communicate using Wi-Fi or our phones. And there are many more things to discover there, from all over the world.\n\nIn this post, I’ll show you fifty things you can find there – all you need is this simple USB dongle and an antenna kit!\n\nA couple of years ago, I heard about the “Make 50 of Something” technique in Vi Hart’s Fifty Fizzbuzzes. Since then, I’ve already made fifty programs for the fantasy console TIC-80 in one weekend in 2021.\n\nI found that a very exciting experience – trying to make so many new things really pushed me to leave my comfort zone, to be creative, and not to get sucked into rabbit holes too deep.\n\nI knew I definitely wanted to try the technique again. So, when I took a week of vacation, I decided to try to find 50 things to do with a Software Defined Radio!\n\nWhat is an SDR?\n\nA Software Defined Radio is essentially a radio that relies on a computer to do most of its data processing. It doesn’t rely on analog hardware too much – instead, most of what is does is “defined in software”, hence the name.\n\nUsually, SDRs can detect electromagnetic waves in a much wider range than a common FM radio, which makes it especially exciting! I got interested in SDRs after reading about Albert’s project to build one as a module for the Framework laptop!\n\nI went into this week without much knowledge of the things I’d find. I’d read through a introductory course for aspiring amateur radio operators (more on that later), but I barely knew which way to point my antenna.\n\nIf you want to follow along, this section is intended to help you get started!\n\nMost of the 50 things also have a little infobox at the beginning, explaining the frequencies, and some special knowledge needed to receive them.\n\nI looked into the topic a bit, and a popular, cheap SDR right now is the RTL-SDR Blog V4, which has the form factor of a simple SUB dongle. You can get it for around $30, or as a kit with telescopic antennas for $50.\n\nEverything I tried during this week was done using this USB dongle, the antenna kit, and a long piece of wire!\n\nI tried to adjust my antenna to the desired frequencies as best as I could. I think for receiving, it’s not super important that your antenna is perfectly configured, though.\n\nFor most applications, I used the dipole antennas that came with the kit I purchased. Dipole antennas have two sides that stick out the same length. You generally wanna make the whole antenna half as long as the wave length you want to receive, and orient it vertically.\n\nMy rule of thumb was to divide 72 by the frequency in MHz, and take that as the length of each side of the dipole in meters. That’d make the whole antenna a bit shorter than half of the wavelength.\n\nFor example, this is what the configuration looked like for frequencies around 100 MHz:\n\nAnd for higher frequencies, I used the tiny screw-on antennas from the kit:\n\nFor specific applications like receiving satellites, or receiving locators for airplanes, I used special configurations, but I’ll discuss these as we go!\n\nThe software I liked best, and which I used for many things, was SDR++. It allows you to explore the frequency spectrum very smoothly, and has a modern user interface!\n\nBut I also used plenty of other software, on Linux in my case. I’ll link to the software as needed below.\n\nOn Monday morning, I was excited to start this project! I sat down at my desk, and got to work!\n\nThis as an obvious first thing to do, as the signals are very strong! I was using the SDR++ software, and it felt very nice browsing around and discovering the stations around me! It reminded me of exploring the radio as a child.\n\nI found a local station that gives 1-hour slots to civic groups, for example!\n\nThis is a special frequency range in Germany: Anyone is allowed to send there, using licensed devices. There are 6 channels.\n\nI think someone was testing their device there when I listened in. :D I heard a “Hellooo?”, then a “Test, test”, and then a “General call to all stations”. Oh, and shortly after a short transmission on channel 3 in a Slavic-sounding language!\n\nFreenet devices have a range of only a couple of kilometers, so these people must have been pretty close! :O\n\nWhile browsing the aviation frequencies, I found this station that reports weather conditions in an endless loop. It seems to be the “Automatic Terminal Information Service” of Hamburg airport!\n\nThanks to that, I found out that the current air pressure was 1011 hPa! :D\n\nListening to “messages not meant for the general public” is not allowed in Germany, so of course I didn’t do that. And if I had accidentally done that, I wouldn’t be allowed to tell you about it. 🙅\n\nThat’s short for “Automatic Dependent Surveillance – Broadcast”. Aircraft send it automatically to be tracked.\n\nFor this, I built my first antenna! From wire and and an antenna connector called “SMA”.\n\nAnd it worked! \\o/ I decoded the signal using the software SDRangel. Fascinating! I saw some big & small airplanes, and even a helicopter!\n\nHow stereo audio is transmitted is really interesting, because it’s backwards-compatible to receivers that don’t support it:\n\nHere, you see the demodulated audio frequency spectrum, as shown in SDRangel. Below 19k Hz, it’s just mono audio. Then, to mark a stereo station, there’s a constant “pilot tone” at 19k Hz! (Outside of what most humans can hear.)\n\nThen, if you double the frequency of the pilot tone, you can derive the sections where the difference of the left & right channel to the mono channel is transmitted!\n\nCorrection: I’ve been told that instead of what I call “left” and “right” in this diagram, the upper frequencies transmit the difference of the left and right channels! That way, the receiver can calculate the left and right channels from the mono signal (which is, esseutially, the sum of left and right).\n\nIf you triple the frequency of the pilot tone, you get to a range where FM stations transmit small amounts of digital metadata, like the name and genre of the station, and the current song! That’s a protocol called Radio Data System.\n\nThis system can also transmit road traffic information! There seemed to be a road closure at “0x64BE”, as decoded by SDRangel.\n\nThe Federal Highway Research Institute publishes an Excel table, where I could look up that this is a town in Lower Saxony!\n\n8: Listen to conversations on the 2-meter amateur radio band\n\nThis is a frequency range reserved for amateur radio operators – for non-commercial use only. You may send on this band after getting a license.\n\nWhat I found here is seemingly a conversation circle facilitated by a relay around 15 km away from here – it takes input on a certain frequency, and outputs an amplified copy of it on another frequency! Klaus, Bernd, Jürgen and Horst were talking about antennas, relays, and Windows XP! 😁\n\nThe SDRangel software also has a demodulator for Digital Audio Broadcast! :O I continue to be amazed by it!\n\nI think this was the first time I’ve received digital radio via air! I saw so many stations, and I’ve only checked a couple of channels.\n\nThe advantage of this digital channel is that there’s no noise. And I even saw a “cover image” in one of the programs!\n\nThis is a frequency range for “Private Mobile Radio”. It’s another of these bands where anyone can transmit using a licensed device!\n\nNot a lot of activity here. I heard “Hello, hellooo!”, “Can you hear me?” and some short transmissions that sounded like a child! :D\n\nThere also seemed to be digital transmissions, but I didn’t know how to decode them yet.\n\nThe range of PMR446 devices is pretty low (a couple of hundred metres in cities), so again, the people must’ve been close!\n\nAfter the first day of SDR experiments, I was amazed how much invisible communication is going on around us in the electromagnetic spectrum at the same time!\n\nI posted each of these things on Mastodon as I went, and asked people for suggestions for more things I could receive.\n\nAt 433 MHz, there’s a frequency band for “industrial, scientific and medical” applications. And wow, there was quite a lot of activity nearby!\n\nUsing the decoder rtl_433, I saw two sensors that output the current temperature, humidity, and air pressure!\n\nThere were also some “IBIS beacons” flying by, which are used in public transportation, so maybe it’s buses driving by?\n\nLater, an “Interlogix Security” device also appeared, reporting “closed switch states” :O\n\nShips send out their status using AIS (Automatic Identification System). And again, I received a lot of them here in Hamburg! :O\n\nI was especially excited to receive data from the MS Stubnitz (a fisher boat that was turned into a culture center/techno club)! It reports its status as “moored”, and its speed as 0.1 knots! :D\n\nAgain, I used the software SDRangel. Apparently, it can also display a 3D map, but I haven’t figured out how to add 3D models…\n• Frequency: 876-959 MHz, I looked up the specific ranges for Germany on Wikipedia\n\nI was curious whether you could tell if someone used their phone! So I borrowed a GSM phone, tuned to the correct frequencies, and made some test calls.\n\nWhat surprised me most: You can kind of “see” the volume at which I was talking!?\n\nIn the recording, the three dense bands at the end were when I was humming into the phone at the other end. This only worked in the “receiving” direction.\n\nI spent all Tuesday afternoon and evening learning about satellites. The program gpredict is really nice to find out when satellites will pass overhead! I learned a lot, including that one satellite I was trying to receive burned up last week! :D\n\nI was super excited when I first received a signal from a NOAA satellite! 🛰️\n\nBut I didn’t manage to decode it properly yet. Maybe my reception was too noisy? I wanted to keep trying, but I had to move on.\n\nIn Germany, the police has switched to an encrypted digital protocol called TETRA.\n\nEven though I’ve seen some interesting talks at CCC events about weaknesses in the decryption, all I wanted to do for now is looking at the pretty signals in SDR++. :3\n\nAgain, this is communication not meant for the general public.\n\nI didn’t listen to someone dispatching taxis to specific addresses, and you also shouldn’t do that either. 🚕\n\nSome of the most fun I had was just browsing frequencies and seeing what I can find! Sometimes, I encountered signals I can’t identify.\n\nFor example, at 865-868 MHz, there was a family of slow, continuous, digital signals that made a nice melody when listened to in single-sideband demodulation!\n\nAnd at 177-180 MHz, there were two very broadband transmissions. Might be TV? But I couldn’t find out what type. (It later turned out that I’d already listened to these signals – it was digital radio, DAB+.)\n\nAs I was browsing around for things to receive, I saw on this tracking website that a radiosonde was just launched in Hamburg! SDRangel could decode its transmission! It had climbed to a height of 7 km, and it’s -17 °C there!\n\nI knew that it would eventually burst and fall back to Earth, and that I could try to get to it and find it!\n\nI decided to go on a field trip, using trains and my bike.\n\nI was following the tracker. The balloon popped earlier than predicted, and I frantically changed travel plans!\n\nEventually, it landed in a forest. I hoped I could get to it! What made this adventure more tricky was that my mobile Internet contract ran out while I was on the go, and my battery was also almost empty.\n\nBut I made it to the forest, and entered it.\n\nAs I circled the site, I encountered a person in their 60s, with a stubbly beard and a blue wool hat. He was looking in the direction of the crash site, and was holding a smartphone, so I asked him whether he also was looking for the radiosonde.\n\nHe was! We looked for it together for half an hour, jumping over small rivers and crawling through the woods, while he gave me a lot of tips related to hunting sondes.\n\nHe told me that he had found around 40 of them so far!\n\nUsually, the sondes keep broadcasting after landing, but this one wasn’t. So he quickly guessed that someone else could’ve taken it. Or maybe it landed in the water and died?\n\nSome pictures of the area we searched:\n\nEventually, we gave up, and walked back to our vehicles. He also is an amateur radio operator, and could answer a couple of questions related to building antennas!\n\nAnd he was right: Someone had been faster than us! The status was changed. So in the end, I didn’t find the sonde. But something that might be even better – a friend!\n\nIn the 2-meter amateur band, there are certain frequencies for the “Automatic Packet Reporting System”. It’s a bit like IP – packets have a “from” and a “to”. They can also broadcast their position, or weather data.\n\nSome stations seem to announce themselves as repeaters, which probably help forward the packets to increase the range.\n\nAnd two people seemed to be on a “fieldday”, and broadcasted their location. :D\n\nI started the day by building an antenna!\n\nThis was going to be a simple “random wire” antenna, to allow me to get better reception in the lower frequencies, which I’ve omitted so far (because I knew it would be much more fun with a better antenna)!\n\nI measured out 21.6 m of wire (which for ✨magic✨ reasons seem to be a good universal antenna length)…\n\n…directly attached it to the center of another SMA connector…\n\n…and draped it all around my room!\n\nPeople on the Internet say that there are many problems with this – that it would be better to have it outside, and that there’s an impedance mismatch between the receiver and the wire.\n\nI could address those problems, but I wanna try how well this works first :)\n\nI’d been learning it a little bit, so if I recorded it and slowed it down, I could understand it: They’re sending their callsigns. These are from Belgium, France, and Italy! \\o/\n\nI compared to my 2-meter dipole antenna, and the reception was definitely better – I can pick up more transmissions, and with much less noise!\n\nThe German Weather Service broadcasts maritime information throughout the day on various shortwave frequencies.\n\nThey use a protocol called RTTY (radioteletype), and it took me a while to decode it. But I found a neat little program called “fldigi”: You can pipe audio to it (single side band modulation), and then if you pick the correct settings (see screenshot), it happily transcribes the messages!\n\nHere’s the station weather reports for the Baltic Sea and Northern Sea!\n\nI found some other strange signals on the 30-meter band. The Signal Identification Wiki was really helpful for figuring out what they were: FT8!\n\nFT8 is quite a new protocol, invented in 2017, and it seems to be super popular right now! It allows you to transmit short messages, and again, people are looking for people to talk to (CQ), saying how well they receive each other, or saying goodbye (73).\n\nThis is the WSJT-X software.\n\n24: Detect whether your notebook is charging\n\nAs I was browsing the very low-frequency bands, I had a strange problem: Sometimes, that would work okayish, sometimes I could even make out voices!\n\nBut other times, it wouldn’t work at all, and everything would be loud, angry noise. Even in regions where I had better reception before!\n\nEventually, I found out how to solve that issue – by unplugging my notebook charger. D’oh! :D\n\nIn the low frequencies, occasionally, you can hear a short chirp! :D These are caused by ionosondes, scientific instruments which measure the properties of the ionosphere by sweeping a wide frequency spectrum.\n\nAnother signal (which I accidentally got in the same screenshot) is a radar system – in this case, according to the Signal Identification Wiki, it’s a “CODAR” system, used to measure the motion of water waves and currents along coasts! :O\n• Frequency: In all amateur bands, especially the ones below 30 MHz\n\nHow do you transmit speech over long distances? You can use “amplitude modulation”, where you change the volume of the carrier frequency to model your audio.\n\nAs a side effect, the bands to the sides of the carrier will contain a signal, as well.\n\nOne trick is to transmit just those sidebands, which saves power! But you have to “guess” the base frequency when listening. Depending on which part you transmit, this is called “lower side band” or “upper side band”.\n\nSDR++ makes it very easy to play with this! :) Here’s someone from Serbia!\n\n28: Listen to AM radio from the other side of the world\n\nAt night, low-frequency radio waves can travel further around the world, because they’re reflected by the layers of the ionosphere! There’s something magical about this.\n\nI put my antenna outside, and I could hear a lot of broadcasting stations! On short-wave.info, you can look up where they are located.\n\nSome stations in China are broadcasting with very high power! Some I could hear were over 7500 km away.\n\nOriginally, I had planned the project to run from Monday to Friday. When I still had 32 things to do in Friday morning, I knew I’d need to extend it. But I hadn’t run out of ideas yet:\n\nAfter I’d looked into the low frequencies on Thursday, I went to a higher band again: The Citizens Band!\n\nThis is the third frequency band I’m aware of where anyone is allowed to transmit – provided that you use a licensed device!\n\nThis is a band where my random wire antenna really came in handy. Without it, I would have had a hard time understanding anything. And even with it, transmissions are extremely noisy.\n\nCB radio is used internationally, especially by truck drivers, it seems.\n\n30: Assess the propagation of radio waves using beacons\n\nThe International Beacon Project runs a network of 18 stations, which take turns transmitting their callsigns at certain frequencies.\n\nUsing this system, you can quickly get a sense of how well radio waves are currently propagating to your location. Clever!\n\nI picked up the beacon from southern Finland! You can see its callsign scrolling away in the video. It’s followed by four dashes send with decreasing power. I only heard the first one…\n\nI would’ve loved to receive DCF77, which powers the radio clocks in Germany! But no matter how hard I listened to 77.5 kHz, there was nothing there. I don’t think my dongle can do that.\n\nSo I used higher frequencies! Russia transmits its “RWM” time signal at 9996 kHz, which beeps every second, with a long beep for the full minute.\n\nNot enough to tell the time, but enough to adjust your wrist watch, I guess!\n• Frequency: 3855, 7880, and 13882.5 kHz (see weatherfax.com for more)\n\nThe German Weather Service broadcasts weather maps throughout the day! You can decode them using fldigi’s “WEFAX-576” setting.\n\nI caught this one only halfway through. According to the schedule, it’s the “Surface weather chart North Atlantic, Europe”!\n\nIf you squint really hard, you can make out the coast of Spain and the Mediterranean Sea on the right side!\n\nI couldn’t stop trying to capture a weather satellite, it’s just too cool to receive an image from space!\n\nThat evening, an American satellite called NOAA-15 passed right over us, so I thought I’d try again. And this time, I got parts of an image! \\o/\n\nThis is real-time data! At night, both transmitted images are infrared recordings.\n\nI recorded the FM signal using SDR++, and then decoded the image using noaa-apt, which also added country outlines.\n\nHere’s what the NOAA-15 weather satellite sounds like, by the way! tick-tock\n\nWhile recording, I noticed something strange: The transmission didn’t happen at the frequency I had expected it to! And also, the frequency changed.\n\nThen it hit me: Doppler effect! At the time of the recording, the frequency was around 4250 Hz higher than expected.\n\nAfter looking up the formula, I calculated a relative speed of 9 km/s! (Which got close to its real speed, 7.5 km/s.)\n\nThese stations send encrypted messages using number sequences, possibly for espionage purposes!\n\nSo why not listen to one? There’s a surprisingly well-maintained database of them on a site call Priyom.\n\nSo I tuned into the next frequency that was listed, and: Bingo!\n\nAllegedly, this was a station in Moscow. That day, it sent “218, 218, 218” in a loop, followed by three long beeps, which is the format of a “null message”.\n\nSo no news for the Russian spies.\n\nThe week was really intense for me. Initially, I thought I’d do 10 things per day, but it turned out that that was too much. I had to learn so many new things.\n\nMany things I tried don’t work on my first attempt. Finding LoRaWAN signals, decoding packet radio, finding something on PMR446, decoding the satellite – those were all things that required a second (or third) attempt.\n\nThis project was exhausting, but also joyful – having committed to it, I got in a nice flow state, where I could focus on it for hours.\n\nOften, I thought: “Okay, this is it. I can’t possibly find more things.” But this is the power of the 50 Things technique: I have to keep looking, leave my comfort zone, be creative, try things I otherwise wouldn’t have tried!\n• Frequency: 14.230, 14.233, 21.340, 28.680, 145.625 MHz seem to be popular\n\nUsing a protocol called “SSTV” (slow-scan television), amateur radio operators send each other postcards! :D\n\nI’ve been browsing the usual frequencies, and tried to decode images using the software QSSTV on Linux. And I accidentally caught a piece of what seems to be a test image!\n\nThere’s a mysterious Russian station broadcasting at 4625 kHz. Sometimes, it sends encrypted voice messages.\n\nBut usually, all it does is send a honking sound every two seconds, to deter other stations from using the same frequency.\n\nThe purpose of the station is unclear, but most theories think it’s military communication.\n\nThis was a bit like trying to catch a rare insect! 🐛\n\nLoRaWAN is a low-power, wide-area networking protocol, intended for “Internet of Things” applications.\n\nYou can see transmission in the lower half of the screenshot! It has a very cute structure: You can see eight “down-chirps”, followed by two “up-chirps”. That’s the header, followed by the payload.\n\nTo look for the signal, I made a “baseband capture” in SDR++, and opened the recording in Sonic Visualizer.\n\nDevices like smoke detectors or meters for water or heat are sending their readings via a protocol called Wireless M-Bus.\n\nAgain, I was surprised by how many devices seem to be around! Thanks for the tip, @envy :)\n\nwmbusmeters is a really nice tool for decoding the messages.\n\nThe chips in my SDR stick are also being used in DVB-T dongles! So, can we watch TV? Unfortunately, no.\n\nFrom what I pieced together, there’s a difference between using the stick in SDR mode (where it sends the full spectrum), and in TV mode (where it sends the decoded video).\n\nIn Germany, there’s now DVB-T2, which my hardware doesn’t support in TV mode. And in SDR mode, the bandwidth is too narrow for DVB-T2. But we can scroll over a channel and look at it! :3\n\nDid a little walk to a big intersection, to see what “device signals” I’d find there at 433 MHz.\n\nI could confirm that the IBIS beacons are in fact being sent by buses! The included “vehicle ID” even matches the white number that’s printed on it.\n\nI also saw some messages from tire pressure monitoring systems in cars! They also include an ID, and usually, the brand of the car! The owners probably aren’t aware how easy it would be to track them… (Thanks, @scy!)\n\nSide note: I wonder why some signals in that band are warped like the one at 433.96 MHz here!\n\nAt first, I thought “Ah, Doppler effect again, it’s coming from a moving car!” But if that’d be the case, that car would be moving at over 700 m/s…\n\nFriends later suspected that this effect is due to weak batteries affecting the crystal in the sending devices, or temperature changes.\n\nSo I caught a satellite again! :D This time, it was school project, the Italian satellite “Max Valier”. It continuously sends Morse code on a beacon frequency.\n\nPretty weak signal, but here’s what I could hear:\n\nSuper happy about this! I got both the name of the satellite, as well as its callsign at the end, and what seems to be some kind of greeting? I later learned that is Morse code shorthand for “and”, and that Manfred and Christa Fuchs were the founders of a company that helped launch the satellite!\n\nThis is another thing that’s not allowed in Germany, so you shouldn’t do it.\n\nPagers use a format called “POCSAG” (Post Office Code Standardisation Advisory Group…), which you should not decode using multimon-ng.\n\nBecause you would find that the content is short and cryptic anyway. It would probably be repeated by several stations all around you, to make sure the whole region is covered.\n\nDo not read the English Wikipedia page! It contains frequencies!\n\nAt this point, I was pretty tired. Focusing on this project for 6 days straight took a lot of energy, and I was always uncertain if I could actually complete all 50 things in that week! But I woke up with a fun idea:\n\n44: Detect when a smartphone is turned on\n\nI was curious whether I could see the NFC transceiver in my smartphone! And yeah, especially using my random wire antenna, this works really well!\n\nMy smartphone seems to emit at the NFC frequency a couple of times per second. And when unlocking the screen, it emits five very strong beeps on that frequency! I can see those from the other side of our apartment.\n\nSurely, these signals are the same for every device, right? 😶\n\nObserve the five beeps here:\n\nPiko and I played around with NFC a bit more, and we found out that when getting close to an NFC tag, a smartphone emits at 13.56 MHz continuously!\n\nSo, we started sending Morse code to each other between rooms, using a smartphone and a library book! :’D\n\nSeems that the shortest signal you can create is 0.7 s long, resulting in a meager communication speed of 3-4 words per minute…\n\nThere are ground stations that emit a signal that allow calculating your angle relative to it! If you receive two, you can determine your position. (Thanks, @fly_it!)\n\nI heard the one close to Hamburg! And SDRangel has a decoder, of course! It calculated angles between 210° and 230°, which is pretty close to the actual value of 224°! I don’t think they are meant to be used from the ground.\n\nThe neat navigational map is from https://skyvector.com!\n\nI spent ages trying to build my own decoder in GNU Radio. But I wasn’t familiar with it at all, and I eventually gave up. Still, that seems to be the software you wanna learn for tasks like these!\n\nBy the way, how the ground stations work is fascinating: In my case, it’s a “Doppler VOR”: It transmits a static frequency via amplitude modulation, and adds another signal that moves around in circles, so you get a Doppler frequency shift.\n\nIf you compare the two, you can calculate the angle!\n\n47: See how low you can go in the frequency spectrum\n\nThis was a fun exploration: What’s the lowest-frequency broadcast I can receive?\n\nThe RTL-SDR Blog V4 stick I’m using has a neat feature – a built-in “upconverter”, which is enabled automatically when you try to listen to frequencies below what the chipset supports. This allows it to receive down to ~500 kHz!\n\nThe first stations that are comprehensible started at 1 MHz for me.\n\n48: See how high you can go in the frequency spectrum\n\nThe chipset in my SDR stick go up to maximum frequency of 1766 MHz. It seems pretty quiet up there, probably because I lack proper antennas. I found these three lines in an amateur band, but they probably originate from the stick itself, or another device.\n\nSo the highest-frequency thing I’ve received is ADS-B at 1090 MHz (see entry #5)! 🎉\n\nWe’ve been over this. Not allowed in Germany. Don’t do it. ⛔\n\nBut if you’re in the US, anyone can purchase a marine radio, and even use it to transmit! :D\n\nJust now, I was wondering whether there are any Android apps for controlling SDRs.\n\nAnd it turned out, the software I liked best that week, SDR++, had an Android version since a couple of weeks! \\o/\n\nSo now I could go track down the source of some of these strange signals! :3\n\nAnd with that, … 🥁 … I was officially done with my “50 things to do with a software defined radio”! 🎉\n\nThis were seven very intense days, where I learned a lot of new things about radio waves and the many things they can be used for!\n\nI was proud! I was tired! I was amazed that all those things I received are all around us, everywhere, all at once – if you know where to look. :O\n\nHere’s some things that I haven’t tried or that haven’t worked:\n• Receiving digital voice modes (SDRangel should be able to do it, but I couldn’t figure it out)\n• Receive something from the ISS\n• Use the GRAVES radar to detect meteors (couldn’t detect it)\n\nAlso, doing things with Wi-Fi/Bluetooth/Zigbee could be fun, but I’d need a more expensive receiver for those frequencies.\n\nSo, was this project in fact a gateway drug to getting an amateur radio license?\n\nYeah, probably. I’d love to transmit something and experiment more! :D\n\nIn Germany, a new license class will be introduced in summer 2024, that’ll allow you to send on the 10-meter, 2-meter and 70-cm bands (the “N class”).\n\nIn fact, there’s a really good German online course that teaches you everything you need to know: 50ohm.de\n\nHighly recommended, even if you’re not planning on getting a license.\n\nFinally, thanks to Piko, Chris, and Cqoicebordel for proof-reading this blog post! <3\n\nYou can add your comment in the Fediverse! Alternatively, drop me a mail at mail@blinry.org. Also, you can support me on Patreon or subscribe to my newsletter",
      "author": "blinry",
      "published_date": null,
      "meta_description": "Last week, I went on an adventure through the electromagnetic spectrum!",
      "word_count": 5244,
      "scraping_method": "goose3"
    },
    {
      "url": "https://noctua.at/en/how-to-make-the-framework-desktop-run-even-quieter",
      "title": "How to make the Framework Desktop run even quieter",
      "content": "Not so long ago, the compact, small form factor PC segment witnessed a significant refreshment with the launch of the Framework desktop PC. If you've missed it and are wondering why this mini-PC is considered so special, it's because it was the first desktop PC to utilise the AMD Ryzen AI Max APU, a processor previously exclusive to laptops.\n\nThe AMD Ryzen AI Max processor stands out for its exceptional speed and integrated graphics performance, frequently surprising users with its gaming capabilities, even on demanding titles. Users often highlight its powerful integrated GPU, which can leverage a massive memory pool (up to 96GB for AI tasks), allowing it to efficiently handle complex AI and deep learning workloads. The raw performance delivered by this chip makes it a worthwhile choice for intensive tasks and creative workflows.\n\nAs a collaborator and partner on the Framework Desktop mini-PC project, our first steps involved integrating our NF-A12x25 fan and a fan duct. This way, we could significantly reduce system noise levels while ensuring safe operating temperatures – you can read more about this here. But can the Framework Desktop be made even quieter? We wanted to leave no stone unturned to find out, so we took it a step further by trying to integrate our signature Noctua fan grill design that debuted on the Seasonic Prime TX-1600 Noctua Edition power supply.\n\nIt must be noted that customer safety and EMC requirements for the mini PC, a standalone electrical item, differ from those for hardware components (such as the PSU) designed to be inside a PC case. The safety standard suggests that ventilation openings on case side panels need to be less than 5mm in diameter. To comply with safety regulations, we created an updated version of the original fan grille as implemented on the Seasonic Prime TX 1600 Noctua Edition power supply featuring more struts and a smaller opening size, ensuring full adherence to these standards. To complement the new grille design, we have also designed a custom, funnel shaped fan duct that makes maximum use of the outermost openings of the custom side panel.\n\nIn combination, the custom side panel and duct design provided a massive noise reduction compared to the stock configuration, particularly in lower fan speed ranges. We have measured around 7 dB(A) lower noise levels at around 50% fan speed, and up to 5 dB(A) lower at higher fan speeds, when compared at the same APU operating temperature.\n\nWhile the custom side panel with our signature Noctua grill as well as the custom fan duct are not slated for mass production at this point, we are more than happy to share the 3D CAD files for everyone who is looking to make their Framework Desktop run even quieter.\n\nBoth the custom side panel and the customised fan ductare available to download at Printables.com for you to 3D-print at home:\n• Custom fan duct to make best use of the custom side panel\n\nFortunately, the quality of 3D printing technologies has advanced so much that you can end up with a nice, clean side panel, which will additionally optimise the sound profile, or bring your APU temperatures down significantly.\n\nIn addition to redesigning and testing the Noctua fan grill, we also evaluated various other scenarios. These included replacing the NF-A12x25 with its G2 variant and incorporating an additional 8cm fan for exhaust purposes. The findings of these tests may prove surprising. The additional NF-A8 PWM fan, which was added as an exhaust fan at the front of the case, yielded slightly lower temperatures, but at the expense of extra noise emission, so it’s not a setup that we would recommend from a performance-to-noise efficiency point of view.\n\nWhile upgrading to an NF-A12x25 G2 does provide some acoustical benefits compared to the stock setup (around 1 to 1.5 dB(A) lower noise levels at the same temperatures), its maximum speed is limited to 1800 RPM, so it cannot match the performance headroom of the 2400 RPM HS-PWM version of the NF-A12x25 that is supplied with the Framework Desktop PC. This high-speed version of the „G1“ fan is a safeguard that ensures the system can maintain full performance in worst-case conditions with high ambient temperatures. In other words, we would only recommend upgrading to the NF-A12x25 G2 if you seek to lower noise levels as much as possible and if you are willing to sacrifice the maximum performance headroom in worst-case scenarios that the G1 HS-PWM fan provides.\n\nIn summary, after a lot of simulation, experimenting and testing, we can conclude that not all tweaks to the Framework Desktop’s cooling setup make sense. However, if you have access to a 3D printer, swapping the stock side panel and fan duct for the custom designed ones can help to make your unit run significantly quieter.",
      "author": null,
      "published_date": null,
      "meta_description": "Designed in Austria, Noctua's premium cooling components are renowned for their superb quietness, exceptional performance and thoroughgoing quality.",
      "word_count": 800,
      "scraping_method": "goose3"
    },
    {
      "url": "https://www.gavi.org/vaccineswork/denmark-close-wiping-out-leading-cancer-causing-hpv-strains-after-vaccine-roll-out",
      "title": "Denmark close to wiping out cancer-causing HPV strains after vaccine roll-out",
      "content": "News from the lab\nHPVSpotlight on HPV\nDenmark close to wiping out leading cancer-causing HPV strains after vaccine roll-out\nA nationwide study suggests infections with human papillomavirus (HPV) types 16 and 18 have been virtually eliminated since vaccination began in 2008 – protecting even unvaccinated women.\n2\nSeptember\n2025\n3\nmin read\nby\nLinda Geddes\nRepublish this article\nRepublish this article\nDisclaimer\nIf you would like to republish this article, please follow these steps: use the HTML below; do not edit the text; include the author’s byline; credit VaccinesWork as the original source; and include the page view counter script.\n<article>\n<h1>\n<span>Denmark close to wiping out leading cancer-causing HPV strains after vaccine roll-out</span>\n</h1>\n<div>\n<div><p>A nationwide study suggests infections with human papillomavirus (HPV) types 16 and 18 have been virtually eliminated since vaccination began in 2008 – protecting even unvaccinated women.</p></div>\n</div>\n<ul>\n<li>\n<b>2\nSeptember\n2025</b>\n</li>\n<li>\n<b class=\"me-2\">by</b>\n<span>\n<a href=\"https://www.gavi.org/vaccineswork/authors/linda-geddes\" hreflang=\"en\">Linda Geddes</a>\n</span>\n</li>\n</ul>\n<div>\n<div>\n<div>\n<div>\n<div>\n<p> </p><p>Denmark has effectively eliminated infections with the two biggest cancer-causing strains of human papillomavirus (HPV) since the vaccine was introduced in 2008, data suggests.</p><p>The research, published in <a href=\"https://www.eurosurveillance.org/content/10.2807/1560-7917.ES.2025.30.27.2400820\"><em>Eurosurveillance</em></a>, could have implications for how vaccinated populations are screened in the coming years – particularly as people increasingly receive vaccines that protect against multiple high-risk types of HPV virus.</p><aside class=\"pquote\"><blockquote><p>Before vaccination, the prevalence of HPV16/18 was between 15 and 17%, which has decreased in vaccinated women to less than one percent by 2021.</p></blockquote><p>- Researchers, <a href=\"https://www.eurosurveillance.org/content/10.2807/1560-7917.ES.2025.30.27.2400820\"><em>Eurosurveillance</em></a></p></aside><h3>Deadly cancer</h3><p>After breast cancer, cervical cancer is the most common type of cancer among women aged 15 to 44 years in Europe, and human papillomavirus (HPV) is the leading cause.</p><p>At least 14 high-risk types of the virus have been identified, and before Denmark introduced the HPV vaccine in 2008, HPV types 16 and 18 accounted for around three quarters (74%) of cervical cancers in the country.</p><p>Initially, girls were offered a vaccine that protected against four types of HPV: 16, 18, plus the lower risk types 6 and 11. However, since 2017, Danish girls have been offered a vaccine that protects against nine types of HPV – including those accounting for approximately 90% of cervical cancers.    </p><div><h4>Have you read?</h4><ul><li><a href=\"https://www.gavi.org/vaccineswork/six-ways-hpv-vaccine-saving-lives\">Six ways the HPV vaccine is saving lives</a></li><li><a href=\"https://www.gavi.org/vaccineswork/hpv-poses-ongoing-threat-older-women-study-finds\">HPV poses ongoing threat for older women, study finds</a></li></ul></div><p>To better understand the impact that these vaccination programmes have had on HPV prevalence as vaccinated girls reach cervical screening age (23 to 64 years in Denmark), Dr Mette Hartmann Nonboe at Zealand University Hospital in Nykøbing Falster and colleagues analysed up to three consecutive cervical cell samples collected from Danish women between 2017 and 2024, when they were 22 to 30 years of age.</p><p>“In 2017, one of the first birth cohorts of women in Denmark who were HPV-vaccinated as teenage girls in 2008 reached the screening age of 23 years,” Nonboe explained.</p><p>“Compared with previous generations, these women are expected to have a considerably lower risk of cervical cancer, and it is pertinent to assess [their] future need for screening.”</p><h3>High-risk HPV elimination</h3><p>The research found that infection with the high-risk HPV types (HPV16/18) covered by the vaccine has been almost eliminated. </p><p>“Before vaccination, the prevalence of HPV16/18 was between 15 and 17%, which has decreased in vaccinated women to less than one percent by 2021,” the researchers said.</p><p>In addition, prevalence of HPV types 16 and 18 in women who had not been vaccinated against HPV was five percent. This strongly suggests that the vaccine has reduced the circulation of these HPV types in general population, to the extent that even unvaccinated women are now less likely to be infected with them – so called “population immunity” – the researchers said.</p><aside class=\"pquote\"><blockquote><p>In 2017, one of the first birth cohorts of women in Denmark who were HPV-vaccinated as teenage girls in 2008 reached the screening age of 23 years. Compared with previous generations, these women are expected to have a considerably lower risk of cervical cancer.</p></blockquote><p>- Mette Hartmann Nonboe, Researcher, <a href=\"https://www.eurosurveillance.org/content/10.2807/1560-7917.ES.2025.30.27.2400820\"><em>Eurosurveillance</em></a></p></aside><p>Despite this good news, roughly one third of women screened during the study period still had infection with high-risk HPV types not covered by the original vaccines – and new infections with these types were more frequent among vaccinated women, compared to unvaccinated ones.</p><p>This is expected to fall once girls who received the more recent ‘nine-valent’ vaccine reach screening age. At this point, the screening guidelines should potentially be reconsidered, Nonboe and colleagues said.</p>\n</div>\n</div>\n</div>\n</div>\n</div>\n<p>\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://www.gavi.org/vaccineswork/denmark-close-wiping-out-leading-cancer-causing-hpv-strains-after-vaccine-roll-out\">Original article</a>\n</p><p>This article was originally published on\n<a target=\"_blank\" rel=\"noopener noreferrer\" href=\"https://www.gavi.org/vaccineswork\">VaccinesWork</a>\n</p><script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':\nnew Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],\nj=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=\n'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);\n})(window,document,'script','dataLayer','GTM-M7H54VD');</script><noscript><iframe src=\"https://www.googletagmanager.com/ns.html?id=GTM-M7H54VD\" height=\"0\" width=\"0\" style=\"display:none;visibility:hidden\"></iframe></noscript></article>\nCopy html\nA plaster is applied to the injection site of a young woman after receiving a vaccination. Credit: Centers for Disease Control and Prevention (CDC)\nDenmark has effectively eliminated infections with the two biggest cancer-causing strains of human papillomavirus (HPV) since the vaccine was introduced in 2008, data suggests.The research, published in Eurosurveillance, could have implications for how vaccinated populations are screened in the coming years – particularly as people increasingly receive vaccines that protect against multiple high-risk types of HPV virus.Deadly cancerAfter breast cancer, cervical cancer is the most common type of cancer among women aged 15 to 44 years in Europe, and human papillomavirus (HPV) is the leading cause.At least 14 high-risk types of the virus have been identified, and before Denmark introduced the HPV vaccine in 2008, HPV types 16 and 18 accounted for around three quarters (74%) of cervical cancers in the country.Initially, girls were offered a vaccine that protected against four types of HPV: 16, 18, plus the lower risk types 6 and 11. However, since 2017, Danish girls have been offered a vaccine that protects against nine types of HPV – including those accounting for approximately 90% of cervical cancers.    Have you read?Six ways the HPV vaccine is saving livesHPV poses ongoing threat for older women, study findsTo better understand the impact that these vaccination programmes have had on HPV prevalence as vaccinated girls reach cervical screening age (23 to 64 years in Denmark), Dr Mette Hartmann Nonboe at Zealand University Hospital in Nykøbing Falster and colleagues analysed up to three consecutive cervical cell samples collected from Danish women between 2017 and 2024, when they were 22 to 30 years of age.“In 2017, one of the first birth cohorts of women in Denmark who were HPV-vaccinated as teenage girls in 2008 reached the screening age of 23 years,” Nonboe explained.“Compared with previous generations, these women are expected to have a considerably lower risk of cervical cancer, and it is pertinent to assess [their] future need for screening.”High-risk HPV eliminationThe research found that infection with the high-risk HPV types (HPV16/18) covered by the vaccine has been almost eliminated. “Before vaccination, the prevalence of HPV16/18 was between 15 and 17%, which has decreased in vaccinated women to less than one percent by 2021,” the researchers said.In addition, prevalence of HPV types 16 and 18 in women who had not been vaccinated against HPV was five percent. This strongly suggests that the vaccine has reduced the circulation of these HPV types in general population, to the extent that even unvaccinated women are now less likely to be infected with them – so called “population immunity” – the researchers said.Despite this good news, roughly one third of women screened during the study period still had infection with high-risk HPV types not covered by the original vaccines – and new infections with these types were more frequent among vaccinated women, compared to unvaccinated ones.This is expected to fall once girls who received the more recent ‘nine-valent’ vaccine reach screening age. At this point, the screening guidelines should potentially be reconsidered, Nonboe and colleagues said.\nMore from Linda Geddes\nView all\nCan MMR vaccines cause autism?\n10\nSep\n2025\n9\nmin read\nverified\nMeaslesMumpsRubellaVaccine safety\nMalaria education could reduce cases by over a fifth, study finds\n8\nSep\n2025\n3\nmin read\nverified\nMalariaSpotlight on malaria\nDenmark close to wiping out leading cancer-causing HPV strains after vaccine roll-out\n2\nSep\n2025\n3\nmin read\nverified\nHPVSpotlight on HPV\nScientists make breakthrough towards ‘universal’ antiviral drugs\n29\nAug\n2025\n3\nmin read\nverified\nResearch summary\nRecommended for you\nSenegal rolls out “six-in-one” jab, making life easier for families and health workers\n16\nSep\n2025\n5\nmin read\nverified\nChild dies from complications of measles years after infection – SSPE explained\n16\nSep\n2025\n3\nmin read\nverified\nA Nigerian father of 21 children decided to give vaccines a shot. His whole community benefited\n15\nSep\n2025\n4\nmin read\nverified\nNo girl left behind: HPV vaccines bring hope to Pakistan\n15\nSep\n2025\n5\nmin read\nverified\nThere’s a new outbreak of Ebola in Africa. Here’s what you need to know\n15\nSep\n2025\n4\nmin read\nverified\nFrom data to decisions: why political economy analysis matters for reaching zero-dose children\n12\nSep\n2025\n6\nmin read\nverified",
      "author": null,
      "published_date": null,
      "meta_description": "A nationwide study suggests infections with human papillomavirus (HPV) types 16 and 18 have been virtually eliminated since vaccination began in 2008 – protecting even unvaccinated women.",
      "word_count": 1489,
      "scraping_method": "beautifulsoup"
    },
    {
      "url": "https://lenowo.org/viewtopic.php?t=31",
      "title": "Doom crash after 2.5 years of real-world runtime confirmed on real hardware",
      "content": "DOOM crash after 2.5 years of real-world runtime confirmed on real hardware\nA discussion group for the most cursed software ideas out there\nPost Reply\nPrint view\n1 post\n• Page 1 of 1\nminki\nSite Admin\nPosts: 13 Joined: 2024-03-25\nLocation: /bin/bash\nContact:\nContact minki\nDOOM crash after 2.5 years of real-world runtime confirmed on real hardware\nQuote\nPost\nby minki » 2025-09-16\nTwo and a half years ago, I started my now longest real-world software experiment. I had read an article about how DOOMs engine works and noticed how a variable for tracking the demo kept being incremented even after the next demo started. This variable was compared with a second one storing its previous value. The issue here being, each incrementation would cause the variable to slowly get closer to an overflow, realistically this would never happen in a normal scenario, although it got me curious on just how long it would take until the game would crash due to this.\nI did a few calculations, I don't remember the specifics of it sadly as it has been over two years since that point and I sadly did not document it back then (or I did, but on a partition I no longer have access to) but I remember having gotten roughly 2 1/2 years of possible runtime before an overflow. Obviously, I wanted to know if this would actually happen in the real game on real hardware.\nSo I set up DOOM on a small PDA, powered through a DIY 18650 based UPS which itself was connected to the USB port of my router for a constant 5V supply. I left the system running and mostly forgot about it.\n... Until today when I noticed a pop-up appearing on the device, not long ago from posting this to the board. The game had crashed, only hours after the two and a half year mark, proving that the variable did indeed overflow and cause the expected hard crash of the game:\nIMG_20250916_224553.jpg (81.99 KiB) Viewed 11946 times\n~-~-~ MSD - Making your old devices useful again since 2022! ~-~-~\nTop\nPost Reply\nPrint view\n1 post\n• Page 1 of 1\nReturn to “Software shenanigans”\nJump to\nCursed Hardware\nSoftware shenanigans",
      "author": null,
      "published_date": null,
      "meta_description": "Two and a half years ago, I started my now longest real-world software experiment. I had read an article about how DOOMs engine works and noticed how a variable",
      "word_count": 374,
      "scraping_method": "beautifulsoup"
    },
    {
      "url": "https://asibahi.github.io/thoughts/a-gentle-introduction-to-z3/",
      "title": "A dumb introduction to z3",
      "content": "Recently I have come across a nice article: Many Hard Leetcode Problems are Easy Constraint Problems, and I figured, I really should learn how to use these things! What else do I really have to do? I have had use for solvers (or as they are commonly called: theorem provers) In a previous article, but then I tried to prove the things with good old algorithms. I looked at at the time, but found the whole concept a bit too opaque. Now however, it seemed a bit easier to get into.\n\nTo be clear, as of writing these words, I have only been looking at reading material for two days. I am in no way an expert, and I have not written anything more complex than a solver for the change counter problem (the first example in the article listed above). So I am writing this really knowing nothing about the underlying theory, theorem provers, or whatever the hell \"unification\" is. There is a good chance you know more about this than I do.\n\nThere are bindings in many popular languages. I will be using 's Rust bindings, because I am more comfortable in Rust than, say, Python or JavaScript. The examples I worked with to understand however, can be found in two nice documents:\n• First is in Python\n\nSolvers are a class of .. tools? libraries? where you input some rules and constraints and have the tool just .. solve it for you. It is not going to be a faster or more optimized solution than a custom made algorithm, but it is much easier to change the rules on the fly.\n\nThere are many real world uses. They are often used for scheduling and resource allocation problems. Consider the common scenario of a school schedule: Mary cannot work on Tuesdays because she needs to take care of her father; John lives far so he cannot give classes before 10; Class 3-A is full of nerds so their math hours are double; city council regulates no outdoor activity after 12; Susan and Sarah hate each other so you should not have them teach the same class; etc. You can either have two teachers work on it for a week, or just pop it in a solver!\n\nThe MiniZinc homepage (another popular solver) has a couple of nice examples: a seating chart, rostering, vehicle routing, grid coloring.\n\nOn that note, you might wonder: why did I go with when MiniZinc has a more colorful homepage and is actually referenced by the article linked at the start of this article? The answer is because has bindings in Rust. That is pretty much it.\n\nDocumentation on and its API use a lot of jargon, which makes the whole thing really difficult to wade into without a previous background. I will explain things as I understand when I get to them, but two things really stand out.\n\nThe first is the word . You see this in the context of arrays and function declarations (we will get to those, I hope). But it has nothing to do with .. well .. sorting. is just the jargon word for types.\n\nThe second one is constants. They are not what a normal person would call constants: they are actually the knobs the solvers use to solve problems. There are two types of constants: free, which are what one would call variables; and interpreted, which is when you'd type an integer literal and clever type machinations turns it into a constant in the solver.\n\nNote that also solvers do not work within the regular type system of the programming language. They have their own types (sorry, sorts), and operations that may or may not map nicely to the language's types and operations. Much of the actual code you are writing is about expressing things in the target solver's language. uses a language called \"SMT-LIB2\" (henceforth called ), apparently. And you can actually write your constraints immediately in said language and have the library consume it. Much of what the bindings is take your code and translate internally to this language before feeding it to the solver.\n\nLet's start with what might be the simplest, dumbest equation. Solve for :\n\nYes, a child (literally) can solve this. But it is nice. Here is the Rust program to solve it.\n\nThis prints out the solution. equals three. Who would have guessed?\n\nThe Rust bindings have some nice ergonomics here. You can simply do and it would do all the bookkeeping behind closed doors to transform the (and the ) into an interpreted constant and have them inserted into the internal model.\n\nThe reason you have to pass in a string in is that this is the name given to the variable in . It does not have to be , it can be anything. Why do the bindings not autogenerate the name for you? Who knows.\n\nIf you print the solver (as in ), you will get the following output in the .\n\nNote that the variable you declared is declared as a function. A free constant is basically a function that takes no input and gives an output (here of sort ). The solver finds which version of the function satisfies the assertions. This also explains the arrow in earlier. evaluates to 3.\n\nIn school, jumping from solving equations with a single variable to equations with two variables was a real jump on complexity. Everything was doubled! Here is a pair of equations we will try to solve next:\n\nHere is the program. I am going to print the result of first, tho. I just made up those numbers!\n\nThis prints out the following:\n\nOh it is . Unsatisfiable. Bummer. This means this cannot be solved as defined.\n\nLet's try changing the type to . The type does not have the same nice ergonomics as apparently, so the code will look slightly uglier. This is the new updated code.\n\nExcellent! Using and printing the model as before gives us the following answer, presented as a nice rational number.\n\nTo actually extract the values programmatically, instead of debug printing , requires some song and dance with the API, but it is simple, really. This is what it would look like.\n\nAs I am sure you know from your high school math, some equations have multiple solutions. Here is a simple one.\n\nThe Rust bindings have a nice method for getting multiple solutions out of a solver, simply called . It works similarly to above, and takes the same parameters with the same output. Here is the complete program. (I am going back to because I am not cool enough for numbers.)\n\nI am not clear really on how to get multiple solutions with the regular followed by method, but this one is easy enough to use. Also, some problems might have infinitely many solutions, so it is advisable to use with the iterator. To demonstrate, I will use the circle equation.\n\nHere is the straightforward script followed by the printed out result. Note that the API creates a unique name for every invocation.\n\nThis goes without saying, but if I used the type in this example it would generate infinite solutions.\n\nThe Coin Change problem is a simple one: given a list of denominations and a total, find the smallest number of coins that add up to said total. Emphasis on smallest. Unlike previous problems, this is an optimization problem. We are looking for a solution that satisfies specific criteria instead of just a solution. Conveniently enough, provides an object which we can use to optimize.\n\nLet us set up the parameters of the problem in plain language. The denominations we have are 1, 5, and 10. We need to give 37 money in the least amount of coins. This is simple enough that we can know the solution is three 10 coins, one 5 coin, and two 1 coins. Let's see if we can get the same result. As usual, code followed by output:\n\nOops. This cannot be right.\n\nI do not really understand why the answer is so nonsensical here. The problem is that really spans the entire natural integers range, so it is accounting for negative amounts of coins. This still does not explain how the optimal solution given is 37 coins. (If you can explain, please let me know.)\n\nThe solution for this is to constrain the amount of coins to be non-negative. So let's do that. Add these assertions somewhere before , and Bob's your uncle.\n\nThat's more like it. Now let's try with different denominations. Something like 10. 9, and 1. Note that the optimal solution for 37 would be: one 10 coin, three 9 coins, and no 1 coins. The greedy solution would fail to catch that. Here is the output of printing the optimizer and the result.\n\nCurrently, the total 37 is hardcoded. But what if I want the answers for a number of different totals? Thankfully, you do not need to build the optimizer from scratch for every total. Instead, use the magical functions and . The first one essentially creates a bookmark in the stack of assertions. The second removes everything above said bookmark, and the bookmark. It is simple really. Here are the solutions from 30 to 39, because why not.\n\nHere is the full . I will spare you the output.\n\nNote that the and API is available for as well. At any rate, back to solving.\n\nThis is a significant jump in complexity, so bear with me. We are going to solve a Sudoku. So let's write the constraints first. We can use Rust's arrays or to organize our s and check their constraints. First, this is the puzzle we are solving:\n\nI will forgo the steps to turn that into a . Instead the code below will get that info from a function.\n\nPrinting the solver after each step lets you debug whether you have your constraints correctly. The printout is over 200 lines long, so let's skip that. All we have to do next is to check the value of each cell in .\n\nAnd this prints out the result. You can verify for yourself whether this is correct or not. Maybe try other puzzles. Or add more constraints. You can even try the Miracle Sudoku.\n\nOne thing of note here: which is how dumb the solver is. Note that if you print out the solver, there is no notion of rows and columns and squares. It does not know any Sudoku tricks like X-wings and what have you. All the data is organized on the Rust side of things, and what is given to the solver is \"these two variables cannot be the same\" over and over and over again. And it just .. tells you what the rest of them are.\n\nAnother thing that is not obvious at first glance, is that it does not check if there is a unique solution. The puzzle may be badly constructed and have multiple solutions, and it will happily give you one, or two, or how many you ask for. It does, however, check if it is unsolvable!\n\nOne of the famous examples of using solvers in production is .. layouting. You have a number of elements and you want to arrange them on a page, or a browser window, or whatever. So let's do a rudimentary version of that.\n\nThe page we are layouting has an arbitrary size of 190mm width by 270mm tall. We are to put three boxes on the page of varying sizes and rules. I am just spitballing the sizes here: first box is 105mm by 140mm; second is 85 by 135, third is 120 by 110. They should not overlap, and like .. that's it?\n\nThis prints out this neat solution:\n\nObviously, all these examples are rather simple. Figuring out how to model the problem in the form of boolean rules and constraints is almost all the challenge. There are some limitations, too: cannot solve equations of the sort ; it cannot call external functions to get values (though there are ways to work around that).\n\nThere is plenty of stuff I have not shown. s, which are nothing like programming language arrays and more mappings from one domain to another. , bit vectors, which allow bitwise operations on their values like and and bit shifting. (Which are the key to solving the Hanging Gardens Problem.) s and s and s and regexes and stuff I have not really looked into. Unfortunately, most resources on the web are a bit heavy on theory, and are not targeted to stupid coders like myself.",
      "author": null,
      "published_date": null,
      "meta_description": "Exploring the world of constraint solvers with very simple examples.",
      "word_count": 2115,
      "scraping_method": "goose3"
    },
    {
      "url": "https://www.jeffgeerling.com/blog/2025/cubesats-are-fascinating-learning-tools-space",
      "title": "CubeSats are fascinating learning tools for space",
      "content": "These are CubeSats. Satellites that are going to space—or at least, the ones I have here are prototypes. But these have one thing in common: they're all powered by either a Raspberry Pi, or a microcontroller.\nThere are already Pis in space, like on Mark Rober's SatGus, on GASPACS, and the Astro Pis on the Space station. Another Pi is going up this weekend, which is why I'm posting this today. I'll get to that one, but I wanted to spend some time talking about two things that fascinate me: Raspberry Pis, and putting them space!\nIn this post, I'll cover:\nWhat is a CubeSat\nWho builds and launches CubeSats\nHow you can build your own CubeSat\nThen for a bonus, in today's video, I interviewed two people helping students launch SilverSat into space (this weekend!), and a YouTuber who I've learned a lot from about track satellites (including CubeSats) from your own backyard!\nThe rest of this post contains a lightly-edited transcript of the video above.\nSo let's dive in.\nWhat's a CubeSat?\nWhat's a CubeSat? Well, it's in the name—it's a satellite that's a cube!\nBut they don't have to be a cube, these smallest ones are '1U', or 10 x 10 x 10 centimeters. You can also find 2U CubeSats, like the taller Build a CubeSat, which is 20 centimeters tall. (Well, technically the current prototype is 1.5U).\nSatGus, Mark Rober's satellite taking space selfies, is a whopping 12U! They needed all that extra space to fit a phone, a mechanism to deploy the phone, a camera to take the selfie, a Raspberry Pi to control the phone, and redundant systems for everything. They've already taken thousands of selfies, and SatGus has me beat. My best Pi might get to 3.4 Gigahertz, but the Pi on SatGus is whizzing through space at almost 17,000 miles per hour. That's 7,570 meters per second for everyone else in the world.\nBut back to CubeSats. Having standards means you can build off existing work for the hard things, like a space-rated Aluminum frame, or the complex EPS, or Electrical Power System board.\nThen you can add in custom parts, like a Pi to run experiments, a communications board with antennas and radios, cameras, sensors, and more!\nAnd these cubesats have normal screw-on antennas, but the way these things are deployed, you only get 10x10x10 centimeters—you can't have an antenna poking out the top. So they use cool things like flexible tape antennas that pop out once your CubeSat deploys.\nWhat else makes CubeSats cool?\nWell, how about price? In the old days, you had to have like $10 million to build a satellite, and $60+ million to launch it into space.\nToday, you can build a space-ready CubeSat using a few thousand dollars of parts. Then you can launch it on a rideshare for... well, $85 grand. Which is a lot, but it's not $60 million-a-lot.\nSo most of us won't be launching one of these things into space, unless maybe you can get a grant. But that doesn't mean they're not useful to us.\nWho builds CubeSats?\nLike with many projects, I love these things for the challenge, the way they break some of my assumptions, like working with Raspberry Pis.\nIf you're building a device that's less than 2 kilograms, has 1.8W of maximum continuous power draw, and needs to be operated remotely—even for just a month—you're immediately going to change your assumptions about how you build things.\nI would hack Home Assistant onto a mini PC to monitor some sensors if I was feeling lazy—but that Mini PC would use an order of magnitude too much power for a CubeSat (much less the internal volume it would occupy).\nOn CubeSats, every millimeter, and every milliAmp has to be accounted for.\nSo to me, CubeSats are like Swiss watches of modern electronics. How many sensors can you fit in one? How much throughput can you get on a tiny radio with a small antenna? Can you get enough power out of tiny solar cells to keep the main flight computer working? How do you control thermals without air? How do you design it so it can recover from a complete power loss?\nEvery step of the way there are challenges; and that's before we even launch one! Someone who I think illustrates this best is Manuel, with his Build a CubeSat project. He's working on this Cubesat:\nHe did a weather balloon launch this year, and he's documenting everything on YouTube.\nHis first launch had many small problems. But also great learning, especially around redundancy and how to get the thing off the launch stand without problems.\nAnd you're not only dealing with hardware, but also with software. And software that, at its core, has to be remotely accessed. And not only remote, but also wireless, meaning anyone else on earth within range can access it too.\nSo how do you keep it secure? That's something Tim from Ethos Labs is also dealing with with this, his T.E.M.P.E.S.T. CubeSat:\nThis thing is actually made to be not secure. It has intentional vulnerabilities, and he uses those to teach people different ways to make their CubeSats more secure.\nYou have complex hardware, running in limited space, with limited power and communications, and you want cram in as much functionality as possible.\nDo you see where I'm going with this? That kind of problem is perfect for the microcontrollers and low-power SBCs that I love testing and playing with every day.\nExcept instead of me worrying about something consuming 10 watts, these guys are looking at a power budget of one watt. Or less!\nThese problems are hard. And not everyone has the patience for a completely custom project like Build a CubeSat, so there are also some small companies building kits to help you learn all these lessons with a little less stress.\nLike what hardware do you need for a 100% self-contained CubeSat? And how do you get it certified for flight on a SpaceX rocket?\nYour own CubeSat\nWell, I'll quickly cover two products that are meant for like STEM classroom education, one from the lower end, and one that's based on a CubeSat that just flew this summer.\nThe first one is the MySat Kit, that you can buy from MySat in Ukraine. It comes with a board powered by an ESP32 with a camera, light sensors, an LED, gyroscope, accelerometer, barometer, clock, and a few other boards. And these are all off-the-shelf components you can buy replacements for or use 'em with other hardware, like a Raspberry Pi.\nThe way it's put together won't hold up on a rocket launch, but it's not meant for that. It's meant to show you how it's built, how you can communicate with it, and that sort of thing.\nIt took like an hour to build, and once I put it together I tried flashing the flight control firmware with my Mac... but I ran into some issues with Arduino IDE, and that's a me problem and not so much a MySat problem. Plus the team behind it has a whole war going on that they've been dealing with, so I'll be patient and try getting it going later.\nThe MySat goes from like $130 for a basic kit where you 3D print your own frame, or up to $300 for a full kit including deployable solar panels.\nOn the higher end, there's RASCube, and Edward Robinson, the 21 year old founder of Robinson Space, sent it over after he saw me posting about CubeSats online.\nThe RASCube comes from Australia, and Edward's mission is to teach students about space through hands-on building.\nI just built this LS version of the cube last week; it's the little brother to their V2 design, which flew in space on a Falcon 9 rocket earlier this year.\nLike MySat, you build the kit with an EPS board for power, a computer board with all the controls, and a radio board that ties in GPS and radio comms.\nThe RASCubes are a bit more expensive, coming in at around $430 each for the LB, and $600 each for the full aluminum V2s. But the price tag on that also covers full lesson plans and resources for teachers.\nI love these things—all the people I've talked to on this journey are motivated by the same thing: learning about space, electronics, and integrating hardware in a new way, and sharing what they learn with others, especially students.\nCubeSat T.E.M.P.E.S.T. and Build a CubeSat\nLike take Build a Cubesat. For that project, everything is open source hardware, and every part of the journey is being documented on YouTube.\nOne thing I learned from the first flight test was how weird it is to have your Pi go from like overheating on the ground, to getting really cold as it goes higher, but then overheating again in the upper atmosphere because there's not enough air to dissipate heat!\nYou start to realize some of the crazy physical conditions you'll deal with on orbit.\nBack down to earth, though, for CubeSat Tempest: the whole reason this exists is to help people learn why security is important, even for a tiny CubeSat. More importantly, Tim Fowler's course teaches people how to secure things like uplinks (see: the ground station pictured above) and flight control systems.\nThere are so many people like Tim, who work in their free time to try to teach about space, or engineering, or just small slices of things like security, using these tactile little cubes you can build and put next to your laptop on a desk.\nIt's crazy to think we're to a point where students can build these things, write flight control software, and even launch 'em into space!\nAnd that brings me to SilverSat.\nSilverSat\nThere's another CubeSat with a Raspberry Pi onboard, and it's launching NET Sunday, at 6:11 p.m. Eastern time, aboard a Falcon 9 rocket. What does NET mean? Well, as I found out when I visited Florida this summer, that means \"No Earlier Than\", and in spaceflight, many things delay launches.\nThe students who built SilverSat are no strangers to delays—they were originally supposed to see their CubeSat launch earlier this year, but the cargo module they were on got damaged during transport, and that delayed them for months.\nI got to talk to two of the adults guiding the students on their first space launch, and I discussed the history of the project (it started up in 2017), how they are supported by NASA's CubeSat Launch Initiative, the importance of amateur radio for CubeSats, and why they chose a Raspberry Pi Zero for their onboard computer.\nThat interview is tucked away in the last half of the video at the top of this post.\nTracking Satellites from your backyard\nAlso in that video, I spoke to Gabe from saveitforparts, and he mentioned it's not that difficult to listen in on satellites on orbit—including amateur CubeSats!\nSilverSat will be broadcasting SSDV (Slow-Scan Digital Video) at set times, and the schedule for that should be posted on their website.\nCheck out the video embedded in this post (near the top), or Gabe's own channel for ideas for tracking satellites. It can be done with under $100 of equipment (usually just an SDR and a cheap antenna).\nInfectious Enthusiasm for Learning (and Teaching)\nI feel like a broken record, but one thing I love, talking to anyone in the CubeSat community is this sense of infectious enthusiasm. And I was going to cut this video out for time, but watching it back, I realized other people would probably enjoy Tim showing off some neat CubeSats in his personal collection as much as I did. So I put up some bonus content on my second channel, Level 2 Jeff; you can watch another 8 minutes of CubeSat hardware below:\nThank you to everyone who taught me about CubeSats for this video and blog post.\nFurther reading\nI took down Starlink (but I haven't cancelled)\nStarlink's current problem is capacity\nGetting my amateur radio (ham) license\ncubesat\nspace\nraspberry pi\nvideo\nyoutube\nmicrocontroller\nsatellite\nAdd new comment\nComments\nа причём тут украина?\nReply\nThe MySat is a project that is built by a small group in Ukraine.\nReply",
      "author": null,
      "published_date": null,
      "meta_description": null,
      "word_count": 2056,
      "scraping_method": "beautifulsoup"
    },
    {
      "url": "https://herman.bearblog.dev/slow-social-media/",
      "title": "Slow Social Media",
      "content": "Slow social media\n16 Sep, 2025\nPeople often assume that I hate social media. And they'd be forgiven for believing that, since I am overtly critical of current social media platforms and the effects they have on individuals and society; and deleted all of my social media accounts back in 2019.\nHowever, the underlying concept of social media is something I resonate with: Stay connected with the people you care about.\nIt's just that the current form of social media is bastardised, and not social at all. Instead of improving relationships and fostering connection, they're advertisement-funded content mills which are explicitly designed and continually refined to keep you engaged, lonely, and unhappy. And once TikTok figured out that short-form video with a recommendation engine is digital crack, all other social media platforms quickly sprang into action to copy their secret sauce.\nMeta basically turned Instagram and Facebook from 'connecting with friends' into 'doom-scrolling random content'. Even Pinterest is starting to look like TikTok! They followed user engagement, but not the underlying preferences of their users. I posit that any for-profit social media will eventually degrade into recommendation media over time.\nI don't think most people using these platforms understand that they are the product. Instagram isn't built for you. It's built for marketers. It's built for celebrities to capitalise on their audiences. It's built for politicians and their cronies to sway sentiment. It's built to be as addictive as possible, and to capitalise on your insecurity and uncomfortability.\nImagine that, society and politics are on the rocks all so a fitness influencer can sell you their \"Abs in 30 days\" training program.\nThese platforms are the quintessential poster child for late-stage capitalism.\nOkay, now that we've established what the problems with current platforms are—what would a non-evil social media platform look like?\nI'd love to see everyone running a blog, and subscribing to the people they care about via RSS. But unfortunately this doesn't scale since it requires effort to put your thoughts down in writing longer than 255 characters. I have many friends who don't even know I have a blog, or what an RSS reader is.\nSo while everyone blogging may be the ideal we can aspire to, let's design a hypothetical social media platform that takes the good aspects of current social media, while creating pro-social incentives.\nThe platform should be about:\nKeeping up with friends, family, and other acquaintances\nConnection (but, you know, real connection)\nImproving relationships\nThoughtful engagement\nThe platform should NOT be about:\nCollecting followers\nSelf-promotion\nAdvertising and marketing\nShort-form video and media entertainment\nIn my opinion, as soon as there is the ability for commercial interests to take hold, they will. The \"follow\" mechanism is a key part of that. I propose that instead of followers we should regress back to the \"friend\" or \"connection\" system where there is a symmetric relationship where both people have to agree to the connection. There is no good reason to have \"followers\" on a platform that is trying to improve relationships. \"Following\" is purely for egotistical or financial gain and breeds parasocial relationships.\nI think there should also be a reasonable cap on the number of connections that can be made. Something like 300 friends sounds right. Any more than that and you're a collector, and not using the platform to foster connection.\nThis feature alone already removes 90% of the marketing interests in the platform. Do you want to make a connection, but are maxed out? You'll need to unfriend someone first.\nThe second necessary element would be a chronological feed with posts from your connections. This turns the platform from an engagement engine into a way to keep up with what everyone else is doing, but importantly, gives you a natural \"end\" to the feed when you start seeing posts you've already viewed. This way when you start scrolling there's an explicit stopping point.\nRelatedly, pagination is more humane than infinite-scroll since it gives users a natural breathing point where they can decide whether they want to keep going. Infinite-scroll is such an obvious user-trap, and I view any website doing it as not having its user's best interests at heart.\nAnd finally, there should be a reasonable cap on the number of times a user can post per day. Roughly 5 times per day feels like the upper threshold of what you can post while being intentional about what it is you're posting. This will keep the feed reasonably populated without one or two people completely overwhelming it.\nThe rest of the platform can be optimised to be as easy-to-use as possible. Something like a mixture between the old Instagram and Twitter, with comments and reactions. No reels or any other recommendation system to keep people engaged to death. And no analytics, since that would be optimising for reach and engagement instead of the stated goal of connection.\nDo I expect a platform like this to succeed? Not by the traditional metrics of success. In the real world it would exist alongside the content mills, which are exciting by design and competing for attention. Could it work in niche groups, or amongst intentional people who are sick of the current platforms? Maybe.\nNaturally, a project like this would have to be funded somehow, and unfortunately very few people are willing to pay $5 per month for software services, even if they use it every day. However, I suspect that a social media platform like this would be manageable enough that a small team could run it fairly cheaply and profitably if they're creative. Perhaps with nothing but donations.\nWho will create this egalitarian social media? Not me, that's for sure. I already have my fair share of work moderating the Bear discovery feed, to the extent I've had to bring on a second moderator (hello Sheena!) to keep it clean of spam and other nasty things that free services on the internet attract.\nThat being said, I would love to see something like this. I'd love to be able to stay connected with friends and family abroad without having my attention sold to the highest bidder.\nIf anyone is working on something like this, I'd be happy to consult.",
      "author": null,
      "published_date": null,
      "meta_description": "How can we design better platforms?",
      "word_count": 1036,
      "scraping_method": "beautifulsoup"
    },
    {
      "url": "https://www.stepsecurity.io/blog/ctrl-tinycolor-and-40-npm-packages-compromised",
      "title": "Shai-Hulud malware attack: Tinycolor and over 40 NPM packages compromised",
      "content": "The NPM ecosystem is facing another critical supply chain attack. The popular @ctrl/tinycolor package, which receives over 2 million weekly downloads, has been compromised along with more than 40 other packages across multiple maintainers. This attack demonstrates a concerning evolution in supply chain threats - the malware includes a self-propagating mechanism that automatically infects downstream packages, creating a cascading compromise across the ecosystem. The compromised versions have been removed from npm.\n\nIn this post, we'll dive deep into the payload's mechanics, including deobfuscated code snippets, API call traces, and diagrams to illustrate the attack chain. Our analysis reveals a Webpack-bundled script (bundle.js) that leverages Node.js modules for reconnaissance, harvesting, and propagation; targeting Linux/macOS devs with access to NPM/GitHub/cloud creds.\n\nTo help the community respond to this incident, StepSecurity hosted a Community Office Hour on September 16th at 1 PM PT. The recording is available here: https://www.youtube.com/watch?v=D9jXoT1rtaQ\n\nThe attack unfolds through a sophisticated multi-stage chain that leverages Node.js's process.env for opportunistic credential access and employs Webpack-bundled modules for modularity. At the core of this attack is a ~3.6MB minified bundle.js file, which executes asynchronously during npm install. This execution is likely triggered via a hijacked postinstall script embedded in the compromised package.json.\n\nThe malware includes a self-propagation mechanism through the NpmModule.updatePackage function. This function queries the NPM registry API to fetch up to 20 packages owned by the maintainer, then force-publishes patches to these packages. This creates a cascading compromise effect, recursively injecting the malicious bundle into dependent ecosystems across the NPM registry.\n\nThe malware repurposes open-source tools like TruffleHog to scan the filesystem for high-entropy secrets. It searches for patterns such as AWS keys using regular expressions like AKIA[0-9A-Z]{16}. Additionally, the malware dumps the entire process.env, capturing transient tokens such as GITHUB_TOKEN and AWS_ACCESS_KEY_ID.\n\nFor cloud-specific operations, the malware enumerates AWS Secrets Manager using SDK pagination and accesses Google Cloud Platform secrets via the @google-cloud/secret-manager API. The malware specifically targets the following credentials:\n\nThe malware establishes persistence by injecting a GitHub Actions workflow file (.github/workflows/shai-hulud-workflow.yml) via a base64-encoded bash script. This workflow triggers on push events and exfiltrates repository secrets using the expression ${{ toJSON(secrets) }} to a command and control endpoint. The malware creates branches by force-merging from the default branch (refs/heads/shai-hulud) using GitHub's /git/refs endpoint.\n\nThe malware aggregates harvested credentials into a JSON payload, which is pretty-printed for readability. It then uploads this data to a new public repository named via the GitHub /user/repos API.\n\nThe entire attack design assumes Linux or macOS execution environments, checking for os.platform() === 'linux' || 'darwin'. It deliberately skips Windows systems. For a visual breakdown, see the attack flow diagram below:\n\nThe compromise begins with a sophisticated minified JavaScript bundle injected into affected packages like @ctrl/tinycolor. This is not rudimentary malware but rather a sophisticated modular engine that uses Webpack chunks to organize OS utilities, cloud SDKs, and API wrappers.\n\nThe payload imports six core modules, each serving a specific function in the attack chain.\n\nThis module calls getSystemInfo() to build a comprehensive system profile containing platform, architecture, platformRaw, and archRaw information. It dumps the entire process.env, capturing sensitive environment variables including AWS_ACCESS_KEY_ID, GITHUB_TOKEN, and other credentials that may be present in the environment.\n\nThe AWS harvesting module validates credentials using the STS AssumeRoleWithWebIdentityCommand. It then enumerates secrets using the @aws-sdk/client-secrets-manager library.\n\nThe module handles errors such as DecryptionFailure or ResourceNotFoundException silently through decorateServiceException wrappers. It targets all AWS regions via endpoint resolution.\n\nThe GCP module uses @google-cloud/secret-manager to list secrets matching the pattern projects//secrets/. It implements pagination using nextPageToken and returns objects containing the secret name and decoded payload. The module fails silently on PERMISSION_DENIED errors without alerting the user.\n\nThis module spawns TruffleHog via child_process.exec('trufflehog filesystem / --json') to scan the entire filesystem. It parses the output for high-entropy matches, such as AWS keys found in ~/.aws/credentials.\n\nThe NPM propagation module parses NPM_TOKEN from either ~/.npmrc or environment variables. After validating the token via the /whoami endpoint, it queries /v1/search?text=maintainer:${username}&size=20 to retrieve packages owned by the maintainer.\n\nThis creates a cascading effect where an infected package leads to compromised maintainer credentials, which in turn infects all other packages maintained by that user.\n\nThe GitHub backdoor module authenticates via the /user endpoint, requiring repo and workflow scopes. After listing organizations, it injects malicious code via a bash script (Module 941).\n\nHere is the line-by-line bash script deconstruction:\n\nThis workflow is executed as soon as the compromised package create a commit with it, which immediately exfiltrates all the secrets.\n\nThe malware builds a comprehensive JSON payload containing system information, environment variables, and data from all modules. It then creates a public repository via the GitHub /repos POST endpoint using the function . The repository is public by default to ensure easy access for the command and control infrastructure.\n\nWe are observing hundreds of such public repositories containing exfiltrated credentials. A GitHub search for \"Shai-Hulud\" repositories reveals the ongoing and widespread nature of this attack, with new repositories being created as more systems execute the compromised packages.\n\nThis exfiltration technique is similar to the Nx supply chain attack we analyzed previously, where attackers also used public GitHub repositories to exfiltrate stolen credentials. This pattern of using GitHub as an exfiltration endpoint appears to be a preferred method for supply chain attackers, as it blends in with normal developer activity and bypasses many traditional security controls.\n\nThese repositories contain sensitive information. The public nature of these repositories means that any attacker can access and potentially misuse these credentials, creating a secondary risk beyond the initial compromise.\n\nThe attack employs several evasion techniques including silent error handling (swallowed via catch {} blocks), no logging output, and disguising TruffleHog execution as a legitimate \"security scan.\"\n\nWe analyzed the malicious payload using StepSecurity Harden-Runner in a GitHub Actions workflow. Harden-Runner successfully flagged the suspicious behavior as anomalous. The public insights from this test reveal how the payload works:\n• The compromised package made unauthorized API calls to during the npm install process\n• These API interactions were flagged as anomalous since legitimate package installations should not be making such external API calls\n\nThese runtime detections confirm the sophisticated nature of the attack, with the malware attempting credential harvesting, self-propagation to other packages, and data exfiltration - all during what appears to be a routine package installation.\n\nThe following indicators can help identify systems affected by this attack:\n\nUse these GitHub search queries to identify potentially compromised repositories across your organization:\n\nReplace with your GitHub organization name and use the following GitHub search query to discover all instance of in your GitHub environment.\n\nTo find malicious branches, you can use the following Bash script:\n• The malicious bundle.js file has a SHA-256 hash of:\n\nThe following packages have been confirmed as compromised:\n\nIf you use any of the affected packages, take these actions immediately:\n\nThe malware harvests credentials from multiple sources. Rotate ALL of the following:\n• Any credentials stored in AWS Secrets Manager or GCP Secret Manager\n\nSince the malware specifically targets AWS Secrets Manager and GCP Secret Manager, you need to audit your cloud infrastructure for unauthorized access. The malware uses API calls to enumerate and exfiltrate secrets, so reviewing audit logs is critical to understanding the scope of compromise.\n\nStart by examining your CloudTrail logs for any suspicious secret access patterns. Look specifically for BatchGetSecretValue, ListSecrets, and GetSecretValue API calls that occurred during the time window when the compromised package may have been installed. Also generate and review IAM credential reports to identify any unusual authentication patterns or newly created access keys.\n\nFor Google Cloud Platform, review your audit logs for any access to the Secret Manager service. The malware uses the @google-cloud/secret-manager library to enumerate secrets, so look for unusual patterns of secret access. Additionally, check for any unauthorized service account key creation, as these could be used for persistent access.\n• Check deploy keys and repository secrets for all projects\n• Set up alerts for any new npm publishes from your organization\n\nThe following steps are applicable only for StepSecurity enterprise customers. If you are not an existing enterprise customer, you can start our 14 day free trial by installing the StepSecurity GitHub App to complete the following recovery step.\n\nThe NPM Cooldown check automatically fails a pull request if it introduces an npm package version that was released within the organization’s configured cooldown period (default: 2 days). Once the cooldown period has passed, the check will clear automatically with no action required. The rationale is simple - most supply chain attacks are detected within the first 24 hours of a malicious package release, and the projects that get compromised are often the ones that rushed to adopt the version immediately. By introducing a short waiting period before allowing new dependencies, teams can reduce their exposure to fresh attacks while still keeping their dependencies up to date.\n\n\n\nHere is an example showing how this check protected a project from using the compromised versions of packages involved in this incident:\n\nWe have added a new control specifically to detect pull requests that upgraded to these compromised packages. You can find the new control on the StepSecurity dashboard.\n\nUse StepSecurity Harden-Runner to detect compromised dependencies in CI/CD\n\nStepSecurity Harden-Runner adds runtime security monitoring to your GitHub Actions workflows, providing visibility into network calls, file system changes, and process executions during CI/CD runs. Harden-Runner detects the compromised nx packages when they are used in CI/CD. Here is a sample Harden-Runner insights page demonstrating this detection:\n\nIf you're already using Harden-Runner, we strongly recommend you review recent anomaly detections in your Harden-Runner dashboard. You can get started with Harden-Runner by following the guide at https://docs.stepsecurity.io/harden-runner.\n\nThe StepSecurity Threat Center provides comprehensive details about this @ctrl/tinycolor compromise and all 40+ affected packages. Access the Threat Center through your dashboard to view IOCs, remediation guidance, and real-time updates as new compromised packages are discovered. Threat alerts are automatically delivered to your SIEM via AWS S3 and webhook integrations, enabling immediate incident response when supply chain attacks occur. Our detection systems identified this attack within minutes of publication, providing early warning before widespread exploitation.\n\nUse StepSecurity Artifact Monitor to detect software releases outside of authorized pipelines\n\nStepSecurity Artifact Monitor provides real-time detection of unauthorized package releases by continuously monitoring your artifacts across package registries. This tool would have flagged this incident by detecting that the compromised versions were published outside of the project's authorized CI/CD pipeline. The monitor tracks release patterns, verifies provenance, and alerts teams when packages are published through unusual channels or from unexpected locations. By implementing Artifact Monitor, organizations can catch supply chain compromises within minutes rather than hours or days, significantly reducing the window of exposure to malicious packages.\n\nLearn more about implementing Artifact Monitor in your security workflow at https://docs.stepsecurity.io/artifact-monitor.\n• The npm security team and package maintainers for their swift response to this incident.\n• @franky47, who promptly notified the community through a GitHub issue\n\nThe collaborative efforts of security researchers, maintainers, and community members continue to be essential in defending against supply chain attacks.",
      "author": null,
      "published_date": null,
      "meta_description": "The popular @ctrl/tinycolor package with over 2 million weekly downloads has been compromised alongside 40+ other NPM packages in a sophisticated supply chain attack dubbed \"Shai-Hulud\". The malware self-propagates across maintainer packages, harvests AWS/GCP/Azure credentials using TruffleHog, and establishes persistence through GitHub Actions backdoors - representing a major escalation in NPM ecosystem threats.",
      "word_count": 1841,
      "scraping_method": "goose3"
    },
    {
      "url": "https://waymo.com/blog/#short-all-systems-go-at-sfo-waymo-has-received-our-pilot-permit",
      "title": "Waymo has received our pilot permit allowing for commercial operations at SFO",
      "content": "All systems go at SFO! Waymo has received our pilot permit allowing for commercial operations at San Francisco International Airport.\n\nWe’ll partner with SFO to prepare our operations at the airport in phases, beginning with employee testing soon ahead of welcoming Bay Area riders. Pickups and dropoffs will initially start at SFO’s Kiss & Fly area – a short AirTrain ride from the terminals – with the intention to explore other locations at the airport in the future.\n\nThis is a major milestone that strengthens Waymo’s impact on the region and offers residents and visitors an innovative way to travel. With years of experience serving riders at Phoenix Sky Harbor (PHX) and operations beginning soon at San Jose Mineta International Airport (SJC), we’re accelerating our efforts to serve more airports in more cities as we scale.\n\n“Across San Francisco, we are expanding safe, reliable, and modern transportation options—supporting our city’s economic comeback, boosting our tourism industry, and connecting residents and visitors to everything our city has to offer,” said Mayor Lurie. “We announced in March that we wanted visitors to be able to ride in a Waymo as soon as they arrived in San Francisco, and today, we are taking another important step to get there.”\n\n“Bringing the Waymo experience to San Francisco International Airport is about more than just a ride—it’s about providing a safe, reliable, magical way for Bay Area residents and global visitors to connect with the places and people that matter most,” said Tekedra Mawakana, co-CEO, Waymo. “We’re grateful for the partnership with SFO and the vision of Mayor Lurie in making this a reality.”",
      "author": null,
      "published_date": null,
      "meta_description": "",
      "word_count": 269,
      "scraping_method": "goose3"
    },
    {
      "url": "https://dayvster.com/blog/in-defense-of-cpp/",
      "title": "In Defense of C++",
      "content": "Dayvi Schuster\n12 min read\nTuesday, September 9, 2025\nIn Defense of C++\nWhy C++ remains a powerful and relevant programming language in today's tech landscape.\nThe Reputation of C++\nC++ has often and frequently been criticized for its complexity, steep learning curve, and most of all for its ability to allow the developers using it to not only shoot themselves in the foot, but to blow off their whole leg in the process. But do these criticisms hold up under scrutiny?\nWell, in this blog post, I aim to tackle some of the most common criticisms of C++ and provide a balanced perspective on its strengths and weaknesses.\nC++ is “Complex”\nC++ is indeed a complex language, with a vast array of features and capabilities. For any one thing you wish to achieve in C++, there are about a dozen different ways to do it, each with its own trade-offs and implications. So, as a developer, how are you to know which approach is the best one for your specific use case? Surely you have to have a deep understanding of the language to make these decisions, right?\nNot really… I mean, don’t get me wrong, it helps, but it’s not a hard requirement. Premature optimization is the root of all evil, and in C++, you can write perfectly fine code without ever needing to worry about the more complex features of the language. You can write simple, readable, and maintainable code in C++ without ever needing to use templates, operator overloading, or any of the other more advanced features of the language.\nThere’s this idea that for everything you want to do in any programming language, you need to use the most efficient and correct approach possible. Python has this with their pythonic way of doing things, Java has this, C# has this, and Go has this. Heck, even something as simple as painting HTML onto a browser needs to be reinvented every couple of years and argued about ad nauseam. Here’s the thing, though, in most cases, there is no one right way to do something. The hallowed “best approach” is often just a matter of personal or team preference. The idea that if you just write your code in the “best” and correct way, you’ll never need to worry about maintaining it is just plain wrong.\nDon’t worry so much about using the “best” approach; worry more about writing code that is easy to read and understand. If you do that, you’ll be fine.\nC++ is “Outdated”\nC++ is very old, in fact, it came out in 1985, to put it into perspective, that’s 4 years before the first version of Windows was released, and 6 years before the first version of Linux came out, or to drive the point even further home, back when the last 8-bit computer was released. So yes, C++ is quite old by any standard. But does that make it outdated?\nHell no it’s not like C++ has just been sitting around unchanged from its 1985 release. C++ has been actively developed and improved upon for over 40 years now, with new features and capabilities being added all the time. The most recent version of the C++ standard, C++20, was released in 2020 and introduced a number of new features and improvements to the language. C++23 has introduced significant enhancements, particularly in the standard library and constexpr capabilities. Notably, concepts, ranges, and coroutines have been expanded, bringing modern programming paradigms to C++ and making the language more powerful and expressive th\nan ever before.\nBut Dave, what we mean by outdated is that other languages have surpassed C++ and provide a better developer experience.\nMatter of personal taste, I guess, C++ is still one of the most widely used programming languages with a huge ecosystem of libraries and tools. It’s used in a wide range of applications, from game development to high-performance computing to embedded systems. Many of the most popular and widely used software applications in the world are written in C++.\nI don’t think C++ is outdated by any stretch of the imagination; you have to bend the definition of outdated quite a bit to make that claim.\nC++ is “Unsafe”\nAh, finally, we get to the big one, and yes, I will draw comparisons to Rust as it’s the “memory safe” language that a lot of people claim will or should replace C++.\nIn fact, let’s get the main point out of the way right now.\nRewrites of C++ codebases to Rust always yield more memory-safe results than before.\nCountless companies have cited how they improved their security or the amount of reported bugs or memory leaks by simply rewriting their C++ codebases in Rust.\nNow is that because of Rust? I’d argue in some small part, yes. However, I think the biggest factor is that any rewrite of an existing codebase is going to yield better results than the original codebase.\nWhen you rewrite a codebase, you have the opportunity to rethink and redesign the architecture, fix bugs, and improve the overall quality of the code. You get to leverage all the lessons learned from the previous implementation, all the issues that were found and fixed, and you already know about. All the headaches that would be too much of a pain to fix in the existing codebase, you can just fix them in the new one.\nImagine if you will that you’ve built a shed, it was a bit wobbly, and you didn’t really understand proper wood joinery when you first built it, so it has a few other issues, like structural integrity and a leaky roof. After a few years, you build a new one, and this time you know all the mistakes you made the first time around, so you build it better, stronger, and more weatherproof. In the process, you decide to replace the materials you’ve previously used, say for example, instead of using maple, you opt for oak. Is it correct to say that the new shed is better only because you used oak instead of maple? Or is that a really small part of the overall improvement?\nThat’s how I feel when I see these companies claim that rewriting their C++ codebases in Rust has made them more memory safe. It’s not because of Rust, it’s because they took the time to rethink and redesign their codebase and implemented all the lessons learned from the previous implementation.\nBut that does not deny the fact that C++ is unsafe.\nYes, C++ can be unsafe if you don’t know what you’re doing. But here’s the thing: all programming languages are unsafe if you don’t know what you’re doing. You can write unsafe code in Rust, you can write unsafe code in Python, you can write unsafe code in JavaScript.\nMemory safety is just one aspect of safety in programming languages; you can still write unsafe code in memory-safe programming languages. Just using Rust will not magically make your application safe; it will just make it a lot harder to have memory leaks or safety issues.\nThe term “unsafe” is a bit too vague in this context, and I think it’s being used as a catch-all term, which to me reeks of marketing speak.\nCan C++ be made safer?\nYes, C++ can be made safer; in fact, it can even be made memory safe. There are a number of libraries and tools available that can help make C++ code safer, such as smart pointers, static analysis tools, and memory sanitizers. Heck, if you wish, you can even add a garbage collector to C++ if you really want to(please don’t).\nBut the easiest and most straightforward way to make C++ safer is to simply learn about smart pointers and use them wherever necessary. Smart pointers are a way to manage memory in C++ without having to manually allocate and deallocate memory. They automatically handle the memory management for you, making it much harder to have memory leaks or dangling pointers. This is the main criticism of C++ in the first place.\nC++ is Hard to Read\nThen don’t write it that way. C++ is a multi-paradigm programming language; you can write procedural code, object-oriented code, functional code, or a mix of all three. You can write simple and readable code in C++ if you want to. You can also write complex and unreadable code in C++ if you want to. It’s all about personal or team preference.\nHere’s a rule of thumb I like to follow for C++: make it look as much like C as you possibly can, and avoid using too many advanced features of the language unless you really need to. Use smart pointers, avoid raw pointers, and use the standard library wherever possible.\nYou can do a heck of a lot of programming by just using C++ as you would C and introducing complexity only when you really need to.\nBut doesn’t that defeat the whole purpose of C++? Why not just use C then?\nC++ is a superset of C you can write C code in C++, and it will work just fine. C++ adds a lot of features and capabilities to C. If you were to start with C, then you are locked with C, and that’s fine for a lot of cases, don’t get me wrong, but C++ gives you the option to use more advanced features of the language when you need them. You can start with C and then gradually introduce C++ features as you need them. You don’t have to use all the features of C++ if you don’t want to.\nAgain, going back to my shed analogy, if you build a shed out of wood, you can always add a metal roof later if you need to. You don’t have to build the whole shed out of metal if you don’t want to.\nC++ has a confusing ecosystem\nC++ has a large ecosystem built over the span of 40 years or so, with a lot of different libraries and tools available. This can make it difficult to know which libraries and tools to use for a specific task. But this is not unique to C++; every programming language has this problem.\nAgain, the simple rule of thumb is to use the standard library wherever possible; it’s well-maintained and has a lot of useful features. For other tasks like networking or GUI development, there are a number of well-known libraries that are widely used and well-maintained. Do some research and find out which libraries are best suited for your specific use case.\nAvoid boost like the plague. Boost is a large collection of libraries that are widely used in the C++ community. However, many of the libraries in boost are outdated and no longer maintained. They also tend to be quite complex and difficult to use. If you can avoid using boost, do so.\nUnless you are writing a large and complex application that requires the specific features provided by Boost, you are better off using other libraries that are more modern and easier to use. Do not add the performance overhead and binary size bloat of Boost to your application unless you really need to.\nC++ is not a good choice for beginners\nProgramming is not a good choice for beginners, woodworking is not a good choice for beginners, and car mechanics is not a good choice for beginners. Programming is hard; it takes time and effort to learn, as all things do. There is no general language that is really good for beginners; everything has its trade-offs.\nFact is, if you wanna get into something like systems programming or game development then starting with Python or JavaScript won’t really help you much. You will eventually need to learn C or C++.\nIf your goal is to become a web developer or data scientist, then start with Python or JavaScript.\nIf you just want a job in the programming industry, I don’t know, learn Java or C#, both great languages that get a lot of undeserved hate, but offer a lot of job opportunities.\nLook, here’s the thing: if you’re just starting out in programming, yeah, it’s gonna be hard no matter what language you choose. I’d actually argue that starting with C or C++ is far better than starting with something that obscures a lot of the underlying concepts of programming, I’d argue further that by starting with Python or Javascript you are doing yourself a disservice in the long run and trading off the pain of learning something when your understanding of a topic is still fresh and malleable for the pain of learning something later when you have a lot more invested in your current understanding of programming.\nBut hey, that’s just my opinion.\nC++ vs Rust: Friends or Rivals?\nRust has earned a lot of love in recent years, and for good reason. It takes memory safety seriously, and its borrow checker enforces discipline that C++ often leaves to the programmer. That said, Rust is still building its ecosystem, and the learning curve can feel just as steep — just in different ways. C++ may not prevent you from shooting yourself in the foot, but it gives you decades of battle-tested tooling, compilers, and libraries that power everything from Chrome to Unreal Engine. In practice, many teams use Rust and C++ together rather than treating them as enemies. Rust shines in new projects where safety is the priority, while C++ continues to dominate legacy systems and performance-critical domains.\nIs C++ Still Used in 2025?\nThe short answer: absolutely. Despite the constant chatter that it’s outdated, C++ remains one of the most widely used languages in the world. Major browsers like Chrome and Firefox are still written in it. Game engines like Unreal run on it. Automotive systems, financial trading platforms, and even AI frameworks lean heavily on C++ for performance and control. New standards (C++20, C++23) keep modernizing the language, ensuring it stays competitive with younger alternatives. If you peel back the layers of most large-scale systems we rely on daily, you’ll almost always find C++ humming away under the hood.\nConclusion\nC++ is a powerful and versatile programming language that has stood the test of time. While it does have its complexities and challenges, it remains a relevant and widely used language in today’s tech landscape.\nWith the right approach and mindset, C++ can be a joy to work with and can yield high-performance and efficient applications. So next time you hear someone criticize C++, take a moment to consider the strengths and capabilities of this venerable language before dismissing it outright.\nHope you enjoyed this blog post. If you did, please consider sharing it with your friends and colleagues. If you have any questions or comments, please feel free to reach out to me on Twitter.\nKeep reading If you liked that one here's another: Zig Error Handling Or explore one of these tags\nBrowse by tag:\nc\nprogramming\nsoftware development\nzig\nsys programming\nlow level\nfrontend\nwebdev\nopinion\njotai\nreact\nreact-query\njavascript\nastro\ntypescript\nstate\nreact hooks\nfullstack\ngithub\nnext.js\nperformance\ncareer\nopen source\ngit\nauth\ncontext\ncsharp\ndotnet\nWanna show support?\nIf you find my sporadic thoughts and ramblings helpful.\nYou can buy me a coffee if you feel like it.\nIt's not necessary but it's always appreciated. The content will always\nstay free regardless.\nBuy me a Coffee",
      "author": "Dayvi Schuster",
      "published_date": null,
      "meta_description": "Why C++ remains a powerful and relevant programming language in today's tech landscape.",
      "word_count": 2573,
      "scraping_method": "beautifulsoup"
    },
    {
      "url": "https://github.com/wait4x/wait4x",
      "title": "Wait4X allows you to wait for a port or a service to enter the requested state",
      "content": "Wait4X helps you wait for services (databases, APIs, message queues, etc.) to be ready before your app or script continues. It's ideal for:\n• CI/CD pipelines: Ensure dependencies are up before tests run\n\nAfter installing, jump to Quick Start to try it out!\n\n🐹 Go Install (for Go users) You can install Wait4X directly from source using Go (requires Go 1.16+): This will place the binary in your or directory.\n\nGet started in seconds! After installing, try these common checks:\n\nFor more, see Usage Examples or Detailed Usage.\n\nHere are some of the most useful Wait4X commands. Click the links for more details!\n• TCP: Wait for a port to be available\n• HTTP: Wait for a web endpoint with status code and body check\n• Redis: Wait for Redis and check for a key\n• Reverse check (wait for port to be free):\n\n\n\nSee Detailed Usage for advanced options and more protocols.\n\nWait for an HTTP(S) endpoint to be ready, with flexible validation options.\n\nCheck for various DNS record types and values.\n• Check if a table exists: If you need to specify a schema for the table existence check, you can use the connection string parameter, for example:\n• Check for key with value (regex):\n• Wait for multiple Kafka brokers (cluster) to be ready:\n\nWait for a shell command to succeed or return a specific exit code.\n\nSee Advanced Features for timeout, retry, backoff, and parallel/reverse checking options.\n\nControl how long Wait4X waits and how often it checks.\n• Waits up to 30 seconds before giving up.\n\nRetry with increasing delays for more efficient waiting (useful for slow-starting services).\n• Enable exponential backoff: Doubles the wait time between retries, up to 30 seconds.\n\nWait for a service to become unavailable (e.g., port to be free, service to stop).\n• Wait for a port to become free:\n• Wait for a service to stop: Use for shutdown/cleanup workflows or to ensure a port is not in use.\n\nRun a command after a successful check (great for CI/CD or startup scripts).\n• Chain multiple commands: Automate your workflow after dependencies are ready.\n\nWait for multiple services at once (all must be ready to continue).\n• Check several services in parallel: Use for microservices, integration tests, or complex startup dependencies.\n\nSee CLI Reference for all available flags and options.\n\nFor more detailed examples with complete code, see the examples/pkg directory. Each example is in its own directory with a runnable file.\n\nWait4X provides a flexible CLI with many commands and options. Here is a summary of the main commands and global flags. For the most up-to-date and detailed information, use the built-in help:\n\nEach command supports its own set of flags. See examples above or run for details.\n\nFor a full list of commands and options, run:\n\nWe welcome contributions of all kinds! Whether you want to fix a bug, add a feature, improve documentation, or help others, you're in the right place.\n• Make your changes (add tests if possible)\n\nFor more details, see CONTRIBUTING.md (if available).\n• ⭐ Star the repo to support the project!\n\nThis project is licensed under the Apache License 2.0 - see the LICENSE file for details.\n\nThe project logo is based on the \"Waiting Man\" character (Zhdun) and is used with attribution to the original creator.",
      "author": null,
      "published_date": null,
      "meta_description": "Wait4X allows you to wait for a port or a service to enter the requested state. - wait4x/wait4x",
      "word_count": 553,
      "scraping_method": "goose3"
    },
    {
      "url": "https://github.com/GPUOpen-Drivers/AMDVLK/discussions/416",
      "title": "AMDVLK (AMD Open Source Driver For Vulkan) project is discontinued",
      "content": "GPUOpen-Drivers\n/\nAMDVLK\nPublic\nNotifications\nYou must be signed in to change notification settings\nFork\n166\nStar\n1.9k\nAMDVLK open-source project is discontinued\n#416\njinjianrong\nannounced in\nAnnouncements\nAMDVLK open-source project is discontinued\n#416\njinjianrong\nSep 15, 2025\n·\n6 comments\n·\n6 replies\nReturn to top\nDiscussion options\nUh oh!\nThere was an error while loading. Please reload this page.\nQuote reply\nedited\nUh oh!\nThere was an error while loading. Please reload this page.\njinjianrong\nSep 15, 2025\nMaintainer\n-\nIn a move to streamline development and strengthen our commitment to the open-source community, AMD is unifying its Linux Vulkan driver strategy and has decided to discontinue the AMDVLK open-source project, throwing our full support behind the RADV driver as the officially supported open-source Vulkan driver for Radeon™ graphics adapters.\nThis consolidation allows us to focus our resources on a single, high-performance codebase that benefits from the incredible work of the entire open-source community. We invite developers and users alike to utilize the RADV driver and contribute to its future.\nLearn more about RADV: Mesa RADV Documentation\nContribute to the code: Mesa GitLab Repository\nWe are excited about this focused path forward and are committed to the continued success of open-source Vulkan on Radeon.\nBeta\nWas this translation helpful?\nGive feedback.\n22\nYou must be logged in to vote\n👍\n37\n👎\n2\n🎉\n7\n❤️\n3\n🚀\n42\n👀\n16\nAll reactions\n👍\n37\n👎\n2\n🎉\n7\n❤️\n3\n🚀\n42\n👀\n16\nReplies:\n6 comments\n·\n6 replies\nComment options\nUh oh!\nThere was an error while loading. Please reload this page.\nQuote reply\nSnektron\nSep 15, 2025\n-\nWhat does this mean for AMDPAL and in particular ROCm on Windows?\nBeta\nWas this translation helpful?\nGive feedback.\n4\nYou must be logged in to vote\nAll reactions\n2 replies\nComment options\nUh oh!\nThere was an error while loading. Please reload this page.\nQuote reply\nFlakebi\nSep 15, 2025\n-\nThe code base is still used for Windows, so I’d expect PAL and HIP on Windows to continue working as it is today.\nBeta\nWas this translation helpful?\nGive feedback.\nAll reactions\nComment options\nUh oh!\nThere was an error while loading. Please reload this page.\nQuote reply\nSnektron\nSep 15, 2025\n-\nBut will those repositories remain open source & under development?\nBeta\nWas this translation helpful?\nGive feedback.\nAll reactions\nComment options\nUh oh!\nThere was an error while loading. Please reload this page.\nQuote reply\nR1chterScale\nSep 15, 2025\n-\nTo clarify, does this mean that AMD will be allocating more engineering resources towards RADV?\nBeta\nWas this translation helpful?\nGive feedback.\n28\nYou must be logged in to vote\nAll reactions\n0 replies\nComment options\nUh oh!\nThere was an error while loading. Please reload this page.\nQuote reply\nLeopard1907\nSep 15, 2025\n-\nWhy pal also got archieved?\nBeta\nWas this translation helpful?\nGive feedback.\n4\nYou must be logged in to vote\nAll reactions\n0 replies\nComment options\nUh oh!\nThere was an error while loading. Please reload this page.\nQuote reply\nGen5551\nSep 15, 2025\n-\nHi all. that is, AMDVLK is no more? and then which Vulkan driver should I use?\nBeta\nWas this translation helpful?\nGive feedback.\n0\nYou must be logged in to vote\n👎\n1\nAll reactions\n👎\n1\n3 replies\nComment options\nUh oh!\nThere was an error while loading. Please reload this page.\nQuote reply\nR1chterScale\nSep 15, 2025\n-\nIt explicitly says which one to use in the announcement. Read it\nBeta\nWas this translation helpful?\nGive feedback.\nAll reactions\nComment options\nUh oh!\nThere was an error while loading. Please reload this page.\nQuote reply\nGen5551\nSep 15, 2025\n-\nOkay..\nBeta\nWas this translation helpful?\nGive feedback.\nAll reactions\nComment options\nUh oh!\nThere was an error while loading. Please reload this page.\nQuote reply\ndotjson01\nSep 16, 2025\n-\nI a using Nvidia 🐥 on ubuntu\nIs it okay?\nBeta\nWas this translation helpful?\nGive feedback.\nAll reactions\nComment options\nUh oh!\nThere was an error while loading. Please reload this page.\nQuote reply\nLaguna720\nSep 15, 2025\n-\nIs this a sign that RADV might come to Windows in the future? The Vulkan driver for Windows is based on AMDVLK...\nBeta\nWas this translation helpful?\nGive feedback.\n8\nYou must be logged in to vote\nAll reactions\n1 reply\nComment options\nUh oh!\nThere was an error while loading. Please reload this page.\nQuote reply\nGreyXor\nSep 16, 2025\n-\nhttps://www.phoronix.com/news/RADV-Windows-XDC-2024\nhttps://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/29945\nhttps://indico.freedesktop.org/event/6/contributions/296/attachments/227/307/2024-10-10%20XDC%202024%20-%20A%20Little%20Windows%20with%20your%20Mesa.pdf\nBeta\nWas this translation helpful?\nGive feedback.\n🚀\n5\nAll reactions\n🚀\n5\nComment options\nUh oh!\nThere was an error while loading. Please reload this page.\nQuote reply\nHammerklavier-cn\nSep 16, 2025\n-\nHow about the pro vulkan driver?\nBeta\nWas this translation helpful?\nGive feedback.\n1\nYou must be logged in to vote\nAll reactions\n0 replies\nSign up for free\nto join this conversation on GitHub.\nAlready have an account?\nSign in to comment\nCategory\n📣\nAnnouncements\nLabels\nNone yet\n10 participants",
      "author": null,
      "published_date": null,
      "meta_description": "AMDVLK open-source project is discontinued",
      "word_count": 842,
      "scraping_method": "beautifulsoup"
    },
    {
      "url": "https://github.com/rowboatlabs/rowboat",
      "title": "Launch HN: Rowboat (YC S24) – Open-source IDE for multi-agent systems",
      "content": "⚡ Build AI agents instantly with natural language | 🔌 Connect tools with one-click integrations | 📂 Power with knowledge by adding documents for RAG | 🔄 Automate workflows by setting up triggers and actions | 🚀 Deploy anywhere via API or SDK\n\n\n\n ☁️ Prefer a hosted version? Use our cloud to starting building agents right away!\n\nTo add tools, RAG, more LLMs, and triggers checkout the Advanced section below.\n\nChat with the copilot to build a meeting-prep workflow, then add a calendar invite as a trigger. Watch the full demo here.\n\nChat with the copilot to build a customer support assistant, then connect your MCP server, and data for RAG. Watch the full demo here.\n\nChat with the copilot to build a personal assistant. Watch the full demo here.\n• Native RAG Support: Enable file uploads and URL scraping with Rowboat's built-in RAG capabilities – see RAG Guide.\n• Custom LLM Providers: Use any LLM provider, including aggregators like OpenRouter and LiteLLM - see Using more LLM providers.\n• Tools & Triggers: Add tools and event triggers (e.g., Gmail, Slack) for automation – see Tools & Triggers.\n• API & SDK: Integrate Rowboat agents directly into your app – see API & SDK docs.\n\nRefer to Docs to learn how to start building agents with Rowboat.",
      "author": null,
      "published_date": null,
      "meta_description": "AI-powered multi-agent builder. Contribute to rowboatlabs/rowboat development by creating an account on GitHub.",
      "word_count": 217,
      "scraping_method": "goose3"
    },
    {
      "url": "https://labs.iximiuz.com/tutorials/container-filesystem-from-scratch",
      "title": "How Container Filesystem Works: Building a Docker-Like Container from Scratch",
      "content": "This tutorial was prepared for you by the iximiuz Labs team. Tutorial\non  Linux, Containers Published: Sep 12, 2025How Container Filesystem Works: Building a Docker-like Container From ScratchOne of the superpowers of containers is their isolated filesystem view -\nfrom inside a container it can look like a full Linux distro, often different from the host.\nRun docker run nginx, and Nginx lands in its familiar Debian userspace no matter what Linux flavor your host runs.\nBut how is that illusion built?In this post, we'll assemble a tiny but realistic, Docker-like container using only stock Linux tools: unshare, mount, and pivot_root.\nNo runtime magic and (almost) no cut corners.\nAlong the way, you'll see why the mount namespace is the bedrock of container isolation,\nwhile other namespaces, such as PID, cgroup, UTS, and even network, play rather complementary roles.By the end - especially if you pair this with the container networking tutorial -\nyou'll be able to spin up fully featured, Docker-style containers using nothing but standard Linux commands.\nThe ultimate goal of every aspiring container guru.PrerequisitesSome prior familiarity with Docker (or Podman, or the like) containersBasic Linux knowledge (shell scripting, general namespace awareness)Filesystem fundamentals (single directory hierarchy, mount table, bind mount, etc.)Visualizing the end resultThe diagram below shows what filesystem isolation looks like when Docker creates a new container.\nIt's all right if the drawing feels overwhelming.\nWith the help of the hands-on exercises in this tutorial,\nwe'll build a comprehensive mental model of how containers work,\nso when we revisit the diagram in the closing section,\nit'll look much more digestible.Click to enlargeWhat exactly does Mount Namespace isolate?Let's do a quick experiment.\nIn Terminal 1, start a new shell session in its own mount namespace:sudo unshare --mount bash\nCopy to clipboardNow in Terminal 2, create a file somewhere on the host's filesystem:echo \"Hello from host's mount namespace\" | sudo tee /opt/marker.txt\nCopy to clipboardSurprisingly or not, when you try locating this file in the newly created mount namespace using the Terminal 1 tab, it'll be there:cat /opt/marker.txt\nCopy to clipboardSo what exactly did we just isolate with unshare --mount? 🤔The answer is - a mount table. Here is how to verify it.\nFrom Terminal 1, mount something:sudo mount --bind /tmp /mnt\nCopy to clipboard💡 The above command uses a bind mount for simplicity,\nbut a regular mount (of a block device) would do, too.Now if you list the contents of the /mnt folder in Terminal 1,\nyou should see the files of the /tmp folder:ls -l /mnt\nCopy to clipboardtotal 12\ndrwx------ 3 root root 4096 Sep 11 14:16 file1\ndrwx------ 3 root root 4096 Sep 11 14:16 file2\n...\nCopy to clipboardBut at the same time, the /mnt folder remained empty in the host mount namespace.\nIf you run the same ls command from Terminal 2,\nyou'll see no files:ls -lah /mnt\nCopy to clipboardtotal 0\nCopy to clipboardFinally, the filesystem \"views\" started diverging between namespaces.\nHowever, we could only achieve it by creating a new mount point.Mount namespaces, visualizedFrom the mount namespace man page:Mount namespaces provide isolation of the list of mounts seen by the processes in each namespace instance.\nThus, the processes in each of the mount namespace instances will see distinct single directory hierarchies.Compare the mount tables by running findmnt from Terminal 1 and Terminal 2:Host namespaceNew namespaceTARGET\nSOURCE\nFSTYPE\nOPTIONS\n/\n/dev/vda\next4\nrw,...\n├─/dev\ndevtmpfs\ndevtmpfs\nrw,...\n│ ├─/dev/shm\ntmpfs\ntmpfs\nrw,...\n│ ├─/dev/pts\ndevpts\ndevpts\nrw,...\n│ └─/dev/mqueue\nmqueue\nmqueue\nrw,...\n├─/proc\nproc\nproc\nrw,...\n├─/sys\nsysfs\nsysfs\nrw,...\n│ ├─/sys/kernel/security\nsecurityfs\nsecurityfs\nrw,...\n│ ├─/sys/fs/cgroup\ncgroup2\ncgroup2\nrw,...\n│ ...\n└─/run\ntmpfs\ntmpfs\nrw,...\n├─/run/lock\ntmpfs\ntmpfs\nrw,...\n└─/run/user/1001\ntmpfs\ntmpfs\nrw,...\nCopy to clipboardTARGET\nSOURCE\nFSTYPE\nOPTIONS\n/\n/dev/vda\next4\nrw,...\n├─/dev\ndevtmpfs\ndevtmpfs\nrw,...\n│ ├─/dev/shm\ntmpfs\ntmpfs\nrw,...\n│ ├─/dev/pts\ndevpts\ndevpts\nrw,...\n│ └─/dev/mqueue\nmqueue\nmqueue\nrw,...\n├─/proc\nproc\nproc\nrw,...\n├─/sys\nsysfs\nsysfs\nrw,...\n│ ├─/sys/kernel/security\nsecurityfs\nsecurityfs\nrw,...\n│ ├─/sys/fs/cgroup\ncgroup2\ncgroup2\nrw,...\n│ ...\n├─/run\ntmpfs\ntmpfs\nrw,...\n│ ├─/run/lock\ntmpfs\ntmpfs\nrw,...\n│ └─/run/user/1001\ntmpfs\ntmpfs\nrw,...\n└─/mnt\n/dev/vda[/tmp] ext4\nrw,...\nCopy to clipboardIn hindsight, it should probably make sense -\nafter all, we are playing with a mount namespace\n(and there is no such thing as filesystem namespaces, for better or worse).💡 Interesting fact: Mount namespaces were the first namespace type added to Linux, appearing in Linux 2.4, ca. 2002.💡 Pro Tip: You can quickly check the current mount namespace of a process using the following command:readlink /proc/$PID/ns/mnt\nCopy to clipboardDifferent inode numbers in the output will indicate different namespaces.\nTry running readlink /proc/self/ns/mnt from Terminal 1 and Terminal 2.What the heck is Mount Propagation?Before we jump to how exactly mount namespaces are applied by Docker an OCI runtime\n(e.g., runc) to create containers,\nwe need to learn about one more important (and related) concept - mount propagation.⚠️ Make sure to exit the namespaced shell in Terminal 1\nbefore proceeding with the commands in this section.If you tried to re-do the experiment from the previous section using the unshare() system call instead of the unshare CLI command,\nthe results might look different.unshare_lite.gopackage main\nimport \"os\"\nimport \"os/exec\"\nimport \"syscall\"\nfunc main() {\nif err := syscall.Unshare(syscall.CLONE_NEWNS); err != nil {\npanic(err)\n}\ncmd := exec.Command(\"bash\")\ncmd.Stdin = os.Stdin\ncmd.Stdout = os.Stdout\ncmd.Stderr = os.Stderr\ncmd.Env = os.Environ()\ncmd.Run()\n}\nCopy to clipboardBuild the above improvised unshare_lite program with:go build -o unshare_lite unshare_lite.go\nCopy to clipboardAnd run it from Terminal 1:sudo ./unshare_lite\nCopy to clipboardThen mount something:mount --bind /tmp /mnt\nCopy to clipboardThis time, the results of the ls -l /mnt will look identical in Terminal 1 and Terminal 2.\nThus, the mount namespace alone may not be enough to provide the mount table isolation.If you compare the mount tables by running findmnt from Terminal 1 and Terminal 2,\nthey will look the same:Host namespaceNew namespaceTARGET\nSOURCE\nFSTYPE\nOPTIONS\n/\n/dev/vda\next4\nrw,...\n├─/dev\ndevtmpfs\ndevtmpfs\nrw,...\n│ ├─/dev/shm\ntmpfs\ntmpfs\nrw,...\n│ ├─/dev/pts\ndevpts\ndevpts\nrw,...\n│ └─/dev/mqueue\nmqueue\nmqueue\nrw,...\n├─/proc\nproc\nproc\nrw,...\n├─/sys\nsysfs\nsysfs\nrw,...\n│ ├─/sys/kernel/security\nsecurityfs\nsecurityfs\nrw,...\n│ ├─/sys/fs/cgroup\ncgroup2\ncgroup2\nrw,...\n│ ...\n├─/run\ntmpfs\ntmpfs\nrw,...\n│ ├─/run/lock\ntmpfs\ntmpfs\nrw,...\n│ └─/run/user/1001\ntmpfs\ntmpfs\nrw,...\n└─/mnt\n/dev/vda[/tmp] ext4\nrw,...\nCopy to clipboardTARGET\nSOURCE\nFSTYPE\nOPTIONS\n/\n/dev/vda\next4\nrw,...\n├─/dev\ndevtmpfs\ndevtmpfs\nrw,...\n│ ├─/dev/shm\ntmpfs\ntmpfs\nrw,...\n│ ├─/dev/pts\ndevpts\ndevpts\nrw,...\n│ └─/dev/mqueue\nmqueue\nmqueue\nrw,...\n├─/proc\nproc\nproc\nrw,...\n├─/sys\nsysfs\nsysfs\nrw,...\n│ ├─/sys/kernel/security\nsecurityfs\nsecurityfs\nrw,...\n│ ├─/sys/fs/cgroup\ncgroup2\ncgroup2\nrw,...\n│ ...\n├─/run\ntmpfs\ntmpfs\nrw,...\n│ ├─/run/lock\ntmpfs\ntmpfs\nrw,...\n│ └─/run/user/1001\ntmpfs\ntmpfs\nrw,...\n└─/mnt\n/dev/vda[/tmp] ext4\nrw,...\nCopy to clipboardWhen you unshare a new mount namespace, it gets a full copy of the mount table of the caller process.\nHowever, changes to the caller's mount table may be propagated to the new mount table and vice versa.But why? 🤔Today, containers can easily be the main \"consumer\" of mount namespaces.\nHowever, the applicability of mount namespaces is not limited to containerization use cases.\nFor example, they can be used to provide per-user views of the filesystem.The original implementation of mount namespaces came out too strict, and it led to tedious repetitive work for system administrators.\nTo alleviate the problem, the kernel was extended with the mechanism of shared subtrees,\nwhich in particular introduced mount event propagation between peer groups (of mount points).Mount event propagation, visualizedFor instance, if multiple users on the system were using separate mount namespaces to isolate their root filesystems,\nwithout mount event propagation, mounting a new shared volume would require N mount operations, where N is equal to the number of users.\nWhile with mount event propagation, system administrators need to mount the volume only once,\nand the change will be replicated in all peer groups, even across different mount namespaces.🤓 Neither kernel documentation nor the mount namespace man page use the term mount propagation -\ninstead, they refer to it as propagation type (of a mount point).\nHowever, the term mount propagation seems to be commonly used in the industry,\nincluding in the Docker (example) and Kubernetes (example) documentation.Mount event propagation is exactly what we've just observed when we tried using the unshare system call directly from a Go program:\nwhen the /tmp folder was bind-mounted to the /mnt folder in the new mount namespace,\nthe original namespace received a mount event and replicated the change creating a similar /tmp:/mnt mount.Hmm... Why didn't it happen when we used the standard unshare command-line tool? 🤔The unshare CLI tool does slightly more than just the unshare() system call.\nYou can sneak a peek under the hood of the unshare CLI with the following strace trick (from a fresh terminal):sudo strace unshare --mount bash\nCopy to clipboardWhen you cut through the noise of the trace, you'll spot these three important system calls done in a sequence:...\nunshare(CLONE_NEWNS)\n= 0\nmount(\"none\", \"/\", NULL, MS_REC|MS_PRIVATE, NULL) = 0\nexecve(\"/usr/bin/bash\", [\"bash\"], 0x7fff03d0e038 /* 19 vars */) = 0\n...\nCopy to clipboardRight after creating a new mount namespace and before executing the bash binary,\nthe unshare command also changed the mount propagation type of the root mount point.\nThe above mount() call is equivalent to the following mount command:mount --make-rprivate /\nCopy to clipboard...which means that in the new mount namespace, the root mount and all its sub-mounts (MS_REC and r in rprivate stand for recursive) become completely isolated from the outside world -\nmounting new filesystems inside the mount namespace won't be noticeable in the caller's (i.e., the host's, in our case) mount namespace and vice versa.💡 Mount propagation type is a property of a mount point.\nSince each mount point belongs to the corresponding mount namespace,\nthe mount propagation type is also a namespace-specific property.\nFor instance, the root mount / can have a shared mount propagation type in one namespace\nand private in another.PrivateSharedSlaveNo mount event propagation between namespaces:sudo unshare --mount --propagation private\nfindmnt -o TARGET,SOURCE,FSTYPE,PROPAGATION\nCopy to clipboardTARGET\nSOURCE\nFSTYPE\nPROPAGATION\n/\n/dev/vda\next4\nprivate\n├─/dev\ndevtmpfs\ndevtmpfs\nprivate\n│ ├─/dev/shm\ntmpfs\ntmpfs\nprivate\n│ ├─/dev/pts\ndevpts\ndevpts\nprivate\n│ └─/dev/mqueue\nmqueue\nmqueue\nprivate\n├─/proc\nproc\nproc\nprivate\n│ └─/proc/sys/fs/binfmt_misc\nsystemd-1\nautofs\nprivate\n│\n└─/proc/sys/fs/binfmt_misc binfmt_misc binfmt_misc private\n├─/sys\nsysfs\nsysfs\nprivate\n│ ├─/sys/kernel/security\nsecurityfs\nsecurityfs\nprivate\n│ ├─/sys/fs/selinux\nselinuxfs\nselinuxfs\nprivate\n│ ...\n└─/run\ntmpfs\ntmpfs\nprivate\n├─/run/lock\ntmpfs\ntmpfs\nprivate\n└─/run/user/1001\ntmpfs\ntmpfs\nprivate\nCopy to clipboardMount events are propagated in both ways:sudo unshare --mount --propagation shared\nfindmnt -o TARGET,SOURCE,FSTYPE,PROPAGATION\nCopy to clipboardTARGET\nSOURCE\nFSTYPE\nPROPAGATION\n/\n/dev/vda\next4\nshared\n├─/dev\ndevtmpfs\ndevtmpfs\nshared\n│ ├─/dev/shm\ntmpfs\ntmpfs\nshared\n│ ├─/dev/pts\ndevpts\ndevpts\nshared\n│ └─/dev/mqueue\nmqueue\nmqueue\nshared\n├─/proc\nproc\nproc\nshared\n│ └─/proc/sys/fs/binfmt_misc\nsystemd-1\nautofs\nshared\n│\n└─/proc/sys/fs/binfmt_misc binfmt_misc binfmt_misc shared\n├─/sys\nsysfs\nsysfs\nshared\n│ ├─/sys/kernel/security\nsecurityfs\nsecurityfs\nshared\n│ ├─/sys/fs/selinux\nselinuxfs\nselinuxfs\nshared\n│ ...\n└─/run\ntmpfs\ntmpfs\nshared\n├─/run/lock\ntmpfs\ntmpfs\nshared\n└─/run/user/1001\ntmpfs\ntmpfs\nshared\nCopy to clipboardMount events are propagated from the caller's namespace to the new one (but not backward):sudo unshare --mount --propagation slave\nfindmnt -o TARGET,SOURCE,FSTYPE,PROPAGATION\nCopy to clipboardTARGET\nSOURCE\nFSTYPE\nPROPAGATION\n/\n/dev/vda\next4\nprivate,slave\n├─/dev\ndevtmpfs\ndevtmpfs\nprivate,slave\n│ ├─/dev/shm\ntmpfs\ntmpfs\nprivate,slave\n│ ├─/dev/pts\ndevpts\ndevpts\nprivate,slave\n│ └─/dev/mqueue\nmqueue\nmqueue\nprivate,slave\n├─/proc\nproc\nproc\nprivate,slave\n│ └─/proc/sys/fs/binfmt_misc\nsystemd-1\nautofs\nprivate,slave\n│\n└─/proc/sys/fs/binfmt_misc binfmt_misc binfmt_misc private,slave\n├─/sys\nsysfs\nsysfs\nprivate,slave\n│ ├─/sys/kernel/security\nsecurityfs\nsecurityfs\nprivate,slave\n│ ├─/sys/fs/selinux\nselinuxfs\nselinuxfs\nprivate,slave\n│ ...\n└─/run\ntmpfs\ntmpfs\nprivate,slave\n├─/run/lock\ntmpfs\ntmpfs\nprivate,slave\n└─/run/user/1001\ntmpfs\ntmpfs\nprivate,slave\nCopy to clipboardWhy does mount propagation matter for us? Two reasons:pivot_root, the modern chroot alternative most container runtimes rely on,\ncomes with its own requirements for the mount propagation type of the involved mount points (we'll see it in the next section).Some applications may want to mount filesystems on the host while running in a container and some others may need to spot the host (or peer containers) mounting filesystems in runtime (e.g., HostToContainer and Bidirectional mount propagations in Kubernetes). More on it later.A naive attempt to isolate container filesystemMount namespaces and propagation are great, but how is all this stuff used in containers?\nLet's try creating a simple container to see this machinery in action.⚠️ Make sure to exit the namespaced shell in Terminal 1\nbefore proceeding with the commands in this section.Preparing container rootfsFirst off, we'll need to prepare the future root filesystem.\nFrom the host's standpoint, each container's rootfs is just a regular folder with some files inside:sudo mkdir -p /opt/container-1/rootfs\nCopy to clipboardFor this experiment, we can \"borrow\" the Alpine filesystem by extracting the alpine:3 image into the directory we just created:crane export alpine:3 | sudo tar -xvC /opt/container-1/rootfs\nCopy to clipboardIf you compare the contents of the /opt/container-1/rootfs and the host's / folders, they will look surprisingly similar:ContainerHosttree -L 1 /opt/container-1/rootfs\nCopy to clipboard/opt/container-1/rootfs/\n├── bin\n├── dev\n├── etc\n├── home\n├── lib\n...\n├── tmp\n├── usr\n└── var\n18 directories, 0 files\nCopy to clipboardtree -L 1 /\nCopy to clipboard/\n├── bin\n├── boot\n├── dev\n├── etc\n├── home\n...\n├── tmp\n├── usr\n└── var\n24 directories, 0 files\nCopy to clipboardHowever, upon closer inspection, you'll see that it's two different Linux distributions:ContainerHostcat /opt/container-1/rootfs/etc/os-release\nCopy to clipboardNAME=\"Alpine Linux\"\nID=alpine\nVERSION_ID=3.22.1\nPRETTY_NAME=\"Alpine Linux v3.22\"\nHOME_URL=\"https://alpinelinux.org/\"\nBUG_REPORT_URL=\"https://gitlab.alpinelinux.org/alpine/aports/-/issues\"\nCopy to clipboardcat /etc/os-release\nCopy to clipboardPRETTY_NAME=\"Ubuntu 24.04.3 LTS\"\nNAME=\"Ubuntu\"\nVERSION_ID=\"24.04\"\nVERSION=\"24.04.3 LTS (Noble Numbat)\"\nVERSION_CODENAME=noble\nID=ubuntu\nCopy to clipboardSwitching to new rootfs (pivot_root)The pivot_root(new_root, put_old) syscall changes the root mount in the mount namespace of the calling process.\nMore precisely, it moves the current root mount of the caller to the directory put_old and makes new_root the new root mount.What it practically means is that by calling pivot_root(\"/opt/container-1/rootfs\") in a new mount namespace,\nwe'll switch to the new root filesystem.💡 From a layman's standpoint, pivot_root is a safer version of chroot - similar effect but no risk of breakouts via forgotten symlinks to the old root filesystem or the double-chroot trick.The pivot_root() call comes with a number of restrictions, in particular:The new_root path must be a mount point, but can't be / (well, attempting pivot_root(\"/\") wouldn't make much sense anyway).The propagation type of the parent mount of new_root and the parent mount of the current root directory must not be shared.If put_old is an existing mount point, its propagation type must not be shared.Expectedly, we only want to perform such a disruptive operation from a separate mount namespace (otherwise, we'd damage the host),\nand the last two restrictions ensure that pivot_root never propagates any mount table changes to another mount namespace:sudo unshare --mount bash\nCopy to clipboardNow let's try satisfying the pivot_root's requirements.\nThe propagation type of the / mount (the parent mount of the current root directory) should not be shared.\nThe above unshare command has likely already set it to private but being explicit won't hurt:mount --make-rprivate /\nCopy to clipboard💡 Interesting fact: runc uses rslave instead of rprivate citing a possibility of a race condition. But both values should be good enough for our demo example.In our case, the /opt/container-1/rootfs folder is not a mount point (it's a regular folder somewhere in the host's filesystem),\nbut we can easily make it a mount point by bind mounting the path onto itself (using a recursive bind mount because hypothetically the container rootfs folder itself can contain sub-mounts):mount --rbind /opt/container-1/rootfs /opt/container-1/rootfs\nCopy to clipboardLastly, ensuring that the propagation type of the new_root itself isn't shared:mount --make-rprivate /opt/container-1/rootfs\nCopy to clipboardNow we're ready to choort pivot the root filesystem:cd /opt/container-1/rootfs\nmkdir .oldroot\nCopy to clipboardpivot_root . .oldroot\nCopy to clipboard...and immediately after that, switch to a shell from the new rootfs because the current bash process may get broken in subtle ways after a pivot_root into a completely different Linux distro (this part is only needed for our demo example -\nreal-world container runtimes usually don't have this issue because they communicate with the kernel directly, using syscalls instead of shell commands):exec /bin/sh\nCopy to clipboardInterestingly, after the pivot_root operation,\ncontainer runtimes are free to set the propagation type of the new root filesystem to pretty much any value\n(shared, slave, private, and even unbindable):mount --make-rslave /\nCopy to clipboard💡 Propagation type of the container root filesystem should not be confused with the propagation type of bind mounts and volumes in Docker and Kubernetes respectively (see below).\nThis is an advanced setting that is often not even exposed through the user-facing APIs of the higher-level container runtimes,\nand the most typical use case for it is nested containers (e.g., DinD).Finally, since you probably don't want the original root filesystem to be accessible in the container,\nthe .oldroot can (and should) be removed right after the pivot_root call:umount -l .oldroot\n# -l stands for \"lazy\" because the fs can be busy\nrm -rf .oldroot\nCopy to clipboardYay! We've just pivoted into a new container. Let's look around:ls -lah /\nCopy to clipboardls -l /\ntotal 68\ndrwxr-xr-x\n2 root\nroot\n4096 Jul 15 10:42 bin\ndrwxr-xr-x\n2 root\nroot\n4096 Sep\n7 12:40 dev\ndrwxr-xr-x\n17 root\nroot\n4096 Jul 15 10:42 etc\ndrwxr-xr-x\n2 root\nroot\n4096 Jul 15 10:42 home\n...\ndrwxr-xr-x\n11 root\nroot\n4096 Jul 15 10:42 var\nCopy to clipboardcat /etc/os-release\nCopy to clipboardNAME=\"Alpine Linux\"\nID=alpine\nVERSION_ID=3.22.1\nPRETTY_NAME=\"Alpine Linux v3.22\"\nHOME_URL=\"https://alpinelinux.org/\"\nBUG_REPORT_URL=\"https://gitlab.alpinelinux.org/alpine/aports/-/issues\"\nCopy to clipboardSo far so good! But if you try listing processes, the output will be empty (which of course can't be true):ps aux\nCopy to clipboardPID\nUSER\nTIME\nCOMMAND\nCopy to clipboardAnd the df command also seems broken:df -ah\nCopy to clipboardFilesystem\nSize\nUsed Available Use% Mounted on\ndf: /proc/mounts: No such file or directory\nCopy to clipboardPreparing a complete container filesystemThe df's error message contained a hint - the /proc folder is empty in the new mount namespace:ls -l /proc\nCopy to clipboardtotal 0\nCopy to clipboardHmm... How come?Well, apparently, not every part of the container root filesystem comes from its image!Similarly to the host, where /proc is populated by the corresponding kernel pseudo filesystem,\ncontainer's /proc needs to be set up separately. And the same goes for /dev and /sys virtual filesystems.On top of that, some special files like /etc/hosts, /etc/hostname, or /etc/resolv.conf should be crafted for each container individually\nbecause the corresponding files in the image (if present) can only contain generic values (e.g., localhost) while Docker typically sets the hostname of a container to a prefix of its random ID and derives the resolv.conf from the eponymous file on the host.Populating /proc pseudo filesystemPopulating the /proc pseudo filesystem is as simple as:mount -t proc proc /proc\nCopy to clipboard💡 In reality, container runtimes usually populate the /proc filesystem before the pivot_root call,\nso the command would look like mount -t proc proc $ROOTFS/proc.However, if you run the above command right away, the /proc filesystem in the container will look exactly the same as the one on the host.\nIn particular, it means that the ps command will start showing the full list of processes on the server,\nwhich is usually undesirable in a container.This is where the PID namespace comes into play.\nWe need to go a few steps back and adjust the unshare command to create not just the mount but also a new PID namespace,\nso that the container's topmost process would become PID 1 and the process hierarchy in the container would start from it:# DO NOT RUN ME\nsudo unshare --mount --pid --fork bash\nCopy to clipboardBut let's not do it just yet...💡 The extra --fork flag above doesn't create any new namespaces, but rather makes unshare create a new process instead of exec'ing the bash command directly.\nThis is a requirement to make the --pid flag actually have the effect on the unshared command\nbecause it's the first child that gets placed into the new PID namespace, not the process that called unshare(CLONE_NEWPID) itself.Populating /dev pseudo filesystemAnother special folder is /dev. On the host, it's typically provided by the devtmpfs and a number of subordinate virtual filesystems\n(from a fresh terminal):findmnt\nCopy to clipboardTARGET\nSOURCE\nFSTYPE\nOPTIONS\n/\n/dev/vda ext4\nrw,relatime,stripe=4\n├─/dev\ndevtmpfs devtmpfs rw,relatime,size=4068368k,nr_inodes=1017092,mode=755\n│ ├─/dev/shm\ntmpfs\ntmpfs\nrw,nosuid,nodev\n│ ├─/dev/pts\ndevpts\ndevpts\nrw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=000\n│ ├─/dev/mqueue\nmqueue\nmqueue\nrw,nosuid,nodev,noexec,relatime\n...\nCopy to clipboardHowever, containers usually get a more limited version of the /dev folder, backed by a regular tmpfs.\nHere is how it can be populated from inside the new mount namespace (back from Terminal 1):mkdir -p /dev\nmount -t tmpfs -o nosuid,strictatime,mode=0755,size=65536k tmpfs /dev\nCopy to clipboard💡 In reality, container runtimes usually populate the /dev filesystem before the pivot_root call,\nso the command would look like mount -t tmpfs ... $ROOTFS/dev.After mounting the /dev tmpfs,\nyou'd need to create special character devices such as /dev/null, /dev/zero, /dev/random, etc.\nHere is how you can do it using the mknod command:mknod -m 666 /dev/null\nc 1 3\nchown root:root /dev/null\nmknod -m 666 /dev/zero\nc 1 5\nchown root:root /dev/zero\n# etc.\nCopy to clipboardThen, mount the subordinate filesystems (/dev/shm, /dev/pts, and /dev/mqueue):mkdir -p /dev/shm\nmount -t tmpfs -o nosuid,nodev,noexec,mode=1777,size=67108864 tmpfs /dev/shm\nCopy to clipboardmkdir -p /dev/pts\nmount -t devpts -o newinstance,ptmxmode=0666,mode=0620 devpts /dev/pts\nCopy to clipboardmkdir -p /dev/mqueue\nmount -t mqueue -o nosuid,nodev,noexec mqueue /dev/mqueue\nCopy to clipboardAnd lastly, set up some well-known symlinks:ln -sf /proc/self/fd\n/dev/fd\nln -sf /proc/self/fd/0 /dev/stdin\nln -sf /proc/self/fd/1 /dev/stdout\nln -sf /proc/self/fd/2 /dev/stderr\nln -sf /proc/kcore\n/dev/core\nCopy to clipboardPopulating /sys pseudo filesystemThe most limited of the containers' pseudo filesystems is probably /sys.\nIt's usually mounted read-only and contains only a few nodes:mount -t sysfs -o ro,nosuid,nodev,noexec sysfs /sys\nCopy to clipboard💡 In reality, container runtimes usually populate the /sys filesystem before the pivot_root call,\nso the command would look like mount -t sysfs ... $ROOTFS/sys.A prominent part of the /sys filesystem is the virtual cgroup filesystem.\nSince a few years ago, Docker and other popular container runtimes started fully isolating the container's cgroup hierarchy by default.\nSimilarly to the /proc filesystem that works best in combination with a new PID namespace,\na new cgroup namespace can be used to make the cgroup2 mount rooted at the host's cgroupfs node that corresponds to the container's topmost process.\nThus, the unshare command would need one more flag, --cgroup:# DO NOT RUN ME\nsudo unshare --mount --pid --fork --cgroup bash\nCopy to clipboardTo mount the cgroup2 filesystem, you can use the following command:mkdir -p /sys/fs/cgroup\nmount -t cgroup2 -o ro,nosuid,nodev,noexec cgroup2 /sys/fs/cgroup\nCopy to clipboardHardening pseudo filesystemsWhile it is not strictly necessary for a demo, real-world container root filesystems usually go through an extra round of hardening.\nFor instance, Docker typically marks a few parts of the /proc filesystem as read-only and masks others, making them completely inaccessible to the containerized app.Here is how you can get a list of sensitive locations that are made read-only by Docker\n(from a fresh terminal):docker container inspect \\\n$(docker run --rm -d alpine:3 sleep 5) \\\n--format '{{join .HostConfig.ReadonlyPaths \"\\n\"}}'\nCopy to clipboard/proc/bus\n/proc/fs\n/proc/irq\n/proc/sys\n/proc/sysrq-trigger\nCopy to clipboardYou can make any file or folder read-only by binding it to itself and remounting it using the ro option:RO_PATH=/proc/bus # or /proc/fs, /proc/irq, etc.\nif [ -e \"$RO_PATH\" ]; then\nmount --bind \"$RO_PATH\" \"$RO_PATH\"\nmount -o remount,bind,ro \"$RO_PATH\"\nfi\nCopy to clipboardSimilarly, here is how you can get a list of locations that are typically made completely inaccessible (through masking) to the containerized app:docker container inspect \\\n$(docker run --rm -d alpine:3 sleep 5) \\\n--format '{{join .HostConfig.MaskedPaths \"\\n\"}}'\nCopy to clipboard/proc/asound\n/proc/acpi\n/proc/interrupts\n/proc/kcore\n/proc/keys\n/proc/latency_stats\n/proc/timer_list\n/proc/timer_stats\n/proc/sched_debug\n/proc/scsi\n/sys/firmware\n/sys/devices/virtual/powercap\nCopy to clipboardMasking of folders and regular files differs. To mask a folder, a read-only tmpfs filesystem can be mounted over it,\nand to mask a regular file, the /dev/null device can be bound to its path.MASKED_FILE=/proc/asound\n# or /proc/interrupts, /proc/kcore, etc.\nmount --bind /dev/null $MASKED_FILE\nMASKED_DIR=/proc/acpi\n# or /proc/scsi, etc.\nmount -t tmpfs -o ro tmpfs $MASKED_DIR\nCopy to clipboard💡\nThe above read-only and masked paths are Docker's defaults for non-privileged containers,\nwhile the OCI Runtime Spec defines only the hardening mechanism and not the exact locations\n(see Masked Paths and Readonly Paths).Preparing special /etc filesSome of the regular files in the container rootfs also require special treatment:/etc/hosts/etc/hostname/etc/resolv.confInspecting these files in the /opt/container-1/rootfs folder right after extracting the Alpine rootfs into it would reveal why:cat /opt/container-1/rootfs/etc/{hosts,hostname,resolv.conf}\nCopy to clipboard# -- /opt/container-1/rootfs/etc/hosts\n127.0.0.1\nlocalhost localhost.localdomain\n::1\nlocalhost localhost.localdomain\n# -- /opt/container-1/rootfs/etc/hostname\nlocalhost\n# -- /opt/container-1/rootfs/etc/resolv.conf\ncat: /opt/container-1/rootfs/resolv.conf: No such file or directory\nCopy to clipboardThe above are some generic values that come directly from the alpine:3 image,\nwhich wouldn't make much sense in any particular container.\nAt the same time, these files would look very different when inspected from a running alpine:3 container:docker run --rm alpine:3 cat /etc/{hosts,hostname,resolv.conf}\nCopy to clipboard# -- /etc/hosts\n127.0.0.1\nlocalhost\n::1\nlocalhost ip6-localhost ip6-loopback\n172.17.0.2\n2f26e97ae70c\n# -- /etc/hostname\n2f26e97ae70c\n# -- /etc/resolv.conf\n# Generated by Docker Engine.\n# This file can be edited; Docker Engine will not make further changes once it\n# has been modified.\nnameserver 168.119.149.157\nnameserver 8.8.8.8\nnameserver 1.1.1.1\n# Based on host file: '/etc/resolv.conf' (legacy)\n# Overrides: []\nCopy to clipboardThus, Docker (or one of its underlying runtimes) replaces the generic /etc/hosts,\n/etc/hostname, and /etc/resolv.conf files from the image with container-specific variants.We can do it, too! Our container has no network interfaces (modulo loopback),\nbut it can still have a proper hostname set (from the host's terminal):cat <<EOF | sudo tee /opt/container-1/hosts\n127.0.0.1\nlocalhost container-1\n::1\nlocalhost ip6-localhost ip6-loopback\nEOF\nCopy to clipboardcat | sudo tee /opt/container-1/hostname <<EOF\ncontainer-1\nEOF\nCopy to clipboardsudo cp /etc/resolv.conf /opt/container-1/resolv.conf\nCopy to clipboard💡 The /etc/resolv.conf file is usually based on the host's /etc/resolv.conf file,\nand then potentially adjusted to the container's needs.The most interesting part is how these files are placed into the container's rootfs.\nInstead of just overwriting the files from the image,\ncontainer runtimes usually mount the container-specific variants of these files on top of the original ones,\neffectively masking them:sudo mount --bind /opt/container-1/hosts /opt/container-1/rootfs/etc/hosts\nsudo mount --bind /opt/container-1/hostname /opt/container-1/rootfs/etc/hostname\nsudo mount --bind /opt/container-1/resolv.conf /opt/container-1/rootfs/etc/resolv.conf\nCopy to clipboardLast but not least, for the container to have its own hostname,\nthe container needs to use a new network and UTS namespaces,\nso the unshare command would need to have two more flags (--uts and --net):# DO NOT RUN ME\nsudo unshare --mount --pid --fork --cgroup --uts --net bash\nCopy to clipboard💡 If we forget to use a new UTS namespace, setting the hostname in the new container will overwrite the host's hostname,\nwhich is something we definitely don't want.\nAnd without a new network namespace, the container simply cannot have its own hostname,\nbecause then it technically has the same network stack as the host (which in particular includes the hostname).Finally, we're ready to prepare a fully isolated container filesystem!Creating a container from scratch (end-to-end example)With all the above lessons learned, let's try creating our second container,\nthis time applying all the necessary namespaces and rootfs adjustments.💡 The below commands are based on the real container preparation steps taken by the runc runtime\nobtained with the following strace trick:# Terminal 1\nsudo strace -f -qqq -e \\\ntrace=/clone,/exec,/unshare,/mount,/mknod,/mkdir,/link,/chdir,/root \\\n-p $(pgrep containerd)\nCopy to clipboard# Terminal 2\ndocker run alpine:3 sleep 9999\nCopy to clipboardStep 1: Prepare rootfs files⚠️ Make sure to exit the namespaced shell in Terminal 1\nbefore proceeding with the commands in this section.The second container will be stored in the /opt/container-2 directory:CONTAINER_DIR=/opt/container-2\nROOTFS_DIR=${CONTAINER_DIR}/rootfs\nCopy to clipboardSimilar to the first container, we'll use the alpine:3 image to \"borrow\" the rootfs files:sudo mkdir -p $ROOTFS_DIR\ncrane export alpine:3 | sudo tar -xvC $ROOTFS_DIR\nCopy to clipboardThis time, we'll create the /etc/hosts, /etc/hostname, and /etc/resolv.conf files beforehand\n(but store them outside of the rootfs dir for now):cat <<EOF | sudo tee $CONTAINER_DIR/hosts\n127.0.0.1\nlocalhost container-2\n::1\nlocalhost ip6-localhost ip6-loopback\nEOF\nCopy to clipboardcat <<EOF | sudo tee $CONTAINER_DIR/hostname\ncontainer-2\nEOF\nCopy to clipboardsudo cp /etc/resolv.conf $CONTAINER_DIR/resolv.conf\nCopy to clipboardStep 2: Create namespacesCreate all the required namespaces with the unshare command (mount, PID, cgroup, UTS, and network):sudo unshare --mount --pid --fork --cgroup --uts --net bash\nCopy to clipboard💡 Other possible namespaces are:ipc - this namespace has no impact on the rootfs creation, so we're skipping it for brevitytime - (optional) not used by Docker or other mainstream container runtimes yetuser - (optional) rootless containers is an advanced topic that deserves its own tutorialStep 3: Isolate new mount namespaceFrom now on, all commands are executed as root and in the new namespaces, so we're skipping the sudo prefix,\nand the CONTAINER_DIR and ROOTFS_DIR variables may need to be re-set:CONTAINER_DIR=/opt/container-2\nROOTFS_DIR=${CONTAINER_DIR}/rootfs\nCopy to clipboardFirst, we need to make sure that no mount events are propagated back to the host's mount namespace:mount --make-rslave /\nCopy to clipboardThen, we need to make sure that the root filesystem itself is a mount point:mount --rbind $ROOTFS_DIR $ROOTFS_DIR\nCopy to clipboard...and that the propagation type of the root filesystem isn't shared:mount --make-private $ROOTFS_DIR\nCopy to clipboardStep 4: Prepare /proc pseudo filesystemMount /proc pseudo filesystem:mkdir -p $ROOTFS_DIR/proc\nmount -t proc proc $ROOTFS_DIR/proc\nCopy to clipboard⚠️ Security Caveat: In untrusted rootfs, $ROOTFS_DIR/<path> can be a symlink pointing outside of $ROOTFS_DIR.\nThis can make the above and many of the below operations corrupt the host system.Real-world container runtimes typically use the openat2() syscall with the RESOLVE_NO_SYMLINKS flag to first open the target file or directory ensuring it's not a symlink,\nand then use mount (or other filesystem operations) on an open file descriptor instead of a textual filename.\nThe latter helps to avoid TOCTTOU vulnerabilities\nwhen the $ROOTFS_DIR contents are changed while the container is being created.However, in a demo context it should be relatively safe to operate with regular filenames.\nSo, we'll do it the simpler way for brevity.Step 5: Prepare /dev pseudo filesystemMount /dev pseudo filesystem as a regular tmpfs:mount -t tmpfs \\\n-o nosuid,strictatime,mode=0755,size=65536k tmpfs \\\n$ROOTFS_DIR/dev\nCopy to clipboardCreate the standard character devices (/dev/null, /dev/zero, /dev/random, etc.):mknod -m 666 \"$ROOTFS_DIR/dev/null\"\nc 1 3\nmknod -m 666 \"$ROOTFS_DIR/dev/zero\"\nc 1 5\nmknod -m 666 \"$ROOTFS_DIR/dev/full\"\nc 1 7\nmknod -m 666 \"$ROOTFS_DIR/dev/random\"\nc 1 8\nmknod -m 666 \"$ROOTFS_DIR/dev/urandom\" c 1 9\nmknod -m 666 \"$ROOTFS_DIR/dev/tty\"\nc 5 0\nchown root:root \"$ROOTFS_DIR/dev/\"{null,zero,full,random,urandom,tty}\nCopy to clipboardCreate typical symlinks:ln -sf /proc/self/fd\n\"$ROOTFS_DIR/dev/fd\"\nln -sf /proc/self/fd/0 \"$ROOTFS_DIR/dev/stdin\"\nln -sf /proc/self/fd/1 \"$ROOTFS_DIR/dev/stdout\"\nln -sf /proc/self/fd/2 \"$ROOTFS_DIR/dev/stderr\"\nln -sf /proc/kcore\n\"$ROOTFS_DIR/dev/core\"\nCopy to clipboardCreate subordinate filesystems (/dev/pts, /dev/shm, /dev/mqueue):mkdir -p \"$ROOTFS_DIR/dev/pts\"\nmount -t devpts \\\n-o newinstance,ptmxmode=0666,mode=0620 devpts \\\n$ROOTFS_DIR/dev/pts\nln -sf /dev/pts/ptmx \"$ROOTFS_DIR/dev/ptmx\"\nCopy to clipboardmkdir -p \"$ROOTFS_DIR/dev/mqueue\"\nmount -t mqueue \\\n-o nosuid,nodev,noexec mqueue \\\n$ROOTFS_DIR/dev/mqueue\nCopy to clipboardmkdir -p \"$ROOTFS_DIR/dev/shm\"\nmount -t tmpfs \\\n-o nosuid,nodev,noexec,mode=1777,size=67108864 tmpfs \\\n$ROOTFS_DIR/dev/shm\nCopy to clipboardStep 6: Prepare /sys pseudo filesystemMount a read-only /sys pseudo filesystem:mkdir -p \"$ROOTFS_DIR/sys\"\nmount -t sysfs \\\n-o ro,nosuid,nodev,noexec sysfs \\\n$ROOTFS_DIR/sys\nCopy to clipboardMount the subordinate cgroup2 filesystem as /sys/fs/cgroup:mkdir -p \"$ROOTFS_DIR/sys/fs/cgroup\"\nmount -t cgroup2 \\\n-o ro,nosuid,nodev,noexec cgroup2 \\\n$ROOTFS_DIR/sys/fs/cgroup\nCopy to clipboardStep 7: Bind hostname, hosts, and resolv.conf filesBind the container-specific hostname, hosts, and resolv.conf files from /opt/container-2,\nmasking the original files in the rootfs' /etc directory:for p in hostname hosts resolv.conf\ndo\ntouch $ROOTFS_DIR/etc/$p\nmount --bind \"$CONTAINER_DIR/$p\" $ROOTFS_DIR/etc/$p\ndone\nCopy to clipboardStep 8: Pivot into the new rootfsFinally, pivot into the fully prepared root filesystem:cd $ROOTFS_DIR\nmkdir -p .oldroot\npivot_root . .oldroot\nCopy to clipboardThis is not something a real runtime would do, but since we use a shell,\nit's better to exec into the target container's shell\nas soon as possible after the pivot_root call:exec /bin/sh\nCopy to clipboardConfigure the propagation type of the container's root filesystem\n(setting it arbitrarily to slave, but the OCI Runtime Specification supports private and even shared):mount --make-rslave /\nCopy to clipboardAnd lastly, getting rid of the link to the old root filesystem:umount -l .oldroot\nrmdir .oldroot\nCopy to clipboardSet the hostname of the container using the value from the container's /etc/hostname file:hostname $(cat /etc/hostname)\nCopy to clipboardStep 9: Harden container filesystemMaking a good part of the /proc filesystem read-only:for d in bus fs irq sys sysrq-trigger\ndo\nif [ -e \"/proc/$d\" ]; then\nmount --bind \"/proc/$d\" \"/proc/$d\"\nmount -o remount,bind,ro \"/proc/$d\"\nfi\ndone\nCopy to clipboardMasking sensitive paths in the /proc and /sys filesystems:for p in \\\n/proc/asound \\\n/proc/interrupts \\\n/proc/kcore \\\n/proc/keys \\\n/proc/latency_stats \\\n/proc/timer_list \\\n/proc/timer_stats \\\n/proc/sched_debug \\\n/proc/acpi \\\n/proc/scsi \\\n/sys/firmware\ndo\nif [ -d \"$p\" ]; then\n# Masking a folder\nmount -t tmpfs -o ro tmpfs $p\nelif [ -f \"$p\" ]; then\n# Masking a regular file\nmount --bind /dev/null $p\nfi\ndone\nCopy to clipboardStep 10: Execute target applicationAt this point, the containerized environment is ready to be used.\nFeel free to look around using the ps, ls, mount, df, hostname,\nand any other commands you can think of, and then exec the containerized application:APP=${APP:-/bin/sh}\nexec $APP\nCopy to clipboardBonus: Sharing host files and folders with containersOne of the very common Docker use cases, especially during local development,\nis sharing files and folders from the host into the container via bind mounts like this:# Traditional -v|--volume flag\ndocker run -v ./data:/data redis\n# More modern but equivalent --mount form\ndocker run --mount type='bind,src=./data,dst=/data' redis\nCopy to clipboardIn the previous section(s), we saw that regular files located on the host can be bind mounted into the future container's root filesystem.\nThis is exactly how Docker runc and similar container runtimes inject the customized /etc/hosts, /etc/hostname, and /etc/resolv.conf files.But the exact same technique can be used to inject any other files or folders from the host into the container.The strace -p $(pgrep containerd) command that we used to reverse engineer the rootfs preparation steps\nwill reveal that the bind mounts of the -v|--volume flag happen right after the pseudo filesystems preparation\nand just before the mounts of the /etc/hosts, /etc/hostname, and /etc/resolv.conf files.And it's a good thing we invested some time in learning about the mount event propagation mechanism -\nDocker allows configuring the propagation type for bind mounts,\nso the following command should not look like a magic spell anymore:docker run -v .:/project:ro,rshared ...\nCopy to clipboardIn the above example, if the containerized application would mount a sub-folder under /project,\nit would be visible on the host as well (and vice versa).\nHowever, the default propagation type of a Docker bind mount is rprivate,\nso don't be surprised if you don't see sub-mounts showing up.Bonus: Adding support for data volumesWhile Docker docs position volumes as a distinct concept,\nunder the hood, they are just bind mounts,\nbut with a few extra features like naming, lifecycle management, and various data source drivers support:# Traditional -v|--volume flag\ndocker run --volume redis-data:/data redis\n# More modern but equivalent --mount form\ndocker run --mount type='volume,src=redis-data,dst=/data' redis\nCopy to clipboardInstead of arbitrary folders on the host, volume data is always stored in /var/lib/docker/volumes/CONTAINER_ID/_data,\nand you can list all existing volumes with the docker volume ls command, or create new ones with docker volume create,\nor even purge them with docker volume rm.\nBut at the end of the day, you're just listing, creating, or removing _data folders in the /var/lib/docker/volumes directory.Interesting that Docker always sets mount propagation for volumes to rprivate (for bind mounts you could tweak it),\nwhile Kubernetes, despite relying on the exact same runc (or the like) runtime under the hood,\nallows more flexible mount propagation configuration (HostToContainer, Bidirectional, etc.).So, in Docker, bind mounts vs. volumes is more of a semantic difference\n(and induced artificial constraints on the data location and propagation type)\nthan an actual technical difference.Where do union filesystems come into play?One of the things we didn't talk about in this article is union filesystems like overlayfs -\nsimply because despite popular belief, they're not mandatory for containers.As we just proved with the above demo, it's possible to create a fully-fledged container without relying on a union filesystem at all.\nDocker uses overlay2 (or an alternative) storage driver to unpack layered container images into \"flat\" local folders.\nHowever, this is only an optimization, mainly focused on the disk space efficiency -\nas we just saw, it's possible to extract a container image filesystem into a regular folder with crane export (or a similar command),\nand the container runtime (e.g., runc) will happily use it as a root filesystem.SummarizingAt the heart of containers lies the mount namespace.\nThat's not an accident - Linux has long treated the filesystem as the central interface for managing processes, devices, and resources.\nOnce you start assembling a root filesystem for a container, it quickly becomes clear that other namespaces -\nPID, cgroup, UTS, and network - are interconnected and much needed to complete the task.This is why walking through the rootfs exercise isn't just an impressive low-level demo you could give at a conference.\nIt's a way to build a comprehensive mental model of how containers work.\nAnd with that model in place, higher-level topics like bind mounts, volumes, mount propagation,\nand persistence in Docker or Kubernetes stop feeling like special cases - they become natural extensions of the same foundation.Ah, and if you made it this far, take another look at the diagram from the opening part -\nit should make much more sense now!Click to enlargeResourcesnamespaces(7) — Linux manual pagemount_namespaces(7) — Linux manual pagemount(2) — Linux manual pagepivot_root(2) — Linux manual pageShared Subtrees - Linux kernel documentationMount namespaces and shared subtrees - LWN.netMount namespaces, mount propagation, and unbindable mounts - LWN.netMounts - OCI Runtime Specificationrootfs_linux.go - runc source codeBind mounts - Docker documentationVolumes - Docker documentationOverlayFS storage driver - Docker documentationMount propagation - Kubernetes documentationMounting into mount namespaces - Christian Brauner's blogAttach a volume to a container while it is running - Jérôme Petazzoni's blogUnderstanding the various mounts setup by a Docker container - Sid Agrawal's blogPractice Level up your Server Side game — Join 13,000 engineers who receive insightful learning materials straight to their inbox\nSubscribe",
      "author": "Ivan Velichko",
      "published_date": null,
      "meta_description": "Learn how Linux containers are built from the ground up. Starting with the mount namespace and a root filesystem, see why PID, cgroup, UTS, and network namespaces naturally follow - and how this foundation makes concepts like bind mounts, volumes, and persistence in Docker or Kubernetes much easier to grasp.",
      "word_count": 6279,
      "scraping_method": "beautifulsoup"
    },
    {
      "url": "https://engelsbergideas.com/reviews/mystery-in-the-moon/",
      "title": "Mystery in the Moon",
      "content": "In the mid-13th century, a Japanese noblewoman embarked on the long journey from Kyoto to Kamakura. Abutsu (c. 1225-83) was a troubled woman: a difficult break-up had forced her to take refuge in a nunnery, and she had experienced extreme poverty as a single mother. But then, she wrote, ‘I decided to forget my countless fears, abandon all thought of myself, and go forth abruptly, enticed by the waning Moon.’ Throughout her journey on the road, it remained a companionable presence, marking time and inspiring her to poetry; often, she admitted, ‘I have gazed simply at the Moon all night long.’\n\nOthers found the Moon a more troubling presence, cold and inconstant. Some thought they could see mysterious creatures on its dappled face: the Korean poet Yun Seon-do (1587-1671) wrote of ‘A jade hare on the Moon [which] pounds out the medicine.’ And, on several terrifying occasions in the late 1170s, the Moon briefly seemed to wriggle and writhe. The monk Gervase of Canterbury, who witnessed this strange phenomenon (which was probably caused by atmospheric turbulence), thought that it looked like ‘a stricken snake… twisted up as though in anxiety’.\n\nSuch fearsome illusions were, fortunately, extremely rare; in contrast, sightings of the man in the Moon were extremely common, though not everyone could see him. The 14th-century mathematician Albert of Saxony complained that, however hard he tried, he saw only black spots. But popular belief in his existence was reinforced by stories of a man who had been exiled to space, either because he had stolen something (maybe cabbages, maybe sheep), or because he had placed thorns on the path to stop people going to church.\n\nSome people seem to have been disturbed by this unfortunate being and his cold, lonely life; in the Middle English poem ‘The Man in the Moon’ (c. 1300), the speaker laments that ‘The Man hears me not, though I cry out to him.’ Others were intrigued by the possibility that there was life out there, and dreamed of space travel. According to legend, the Emperor Xuanzong (r. 712-56) was sent to the Moon by the goddess Chang’e, while Ludovico Ariosto’s The Frenzy of Orlando (1532) imagined the knight Astolfo’s journey to the Moon to recover his cousin’s lost wits. There he discovered an impressive civilisation (‘Cities and castles on the Moon abound/ The size of houses with amazement fills’), as well as vast amounts of earthly detritus; in one of these huge piles of broken promises, lovers’ sighs, and tears, he found Orlando’s lost reason, safely stored as liquid in a corked flask.\n\nMedieval writers also imagined what might happen if Moon-dwellers came to Earth. Some of these fantasies were rather sinister: Geoffrey of Monmouth’s History of the Kings of Britain (c. 1136) included stories of incubus demons who frequently travelled back and forth between Earth and the Moon, when they were not busy having sex with human women. But others, such as The Tale of the Bamboo Cutter, are rather moving. In this tenth-century Japanese story, an elderly couple find and raise a tiny child. She grows up to be a beautiful young woman, loving and popular; even the Emperor becomes her friend. But things are not as they seem, for Kaguya-hime is a Moon-princess, and soon her people arrive to rescue her from this ‘filthy place’. Carrying her off in a silk-canopied chariot, they drape her in a feather robe which makes her forget her earthly friends, so that she cannot remember those who grieve for her.\n\nNevertheless, it offers intriguing comparative insights; we learn, for example, that the Moon was a popular image in many religions, albeit one that was used in contradictory ways. Christian theologians liked to explain that, just as the Moon reflects the light of the Sun, so the Church reflects the light of God. Pope Innocent III came up with an alternative metaphor: for him, the Pope was the Sun, and the Holy Roman Emperor a mere moon reflecting the glorious papal light. Similarly, in Ancrene Wisse (a 13th-century handbook for female recluses) the Moon serves as a symbol of female foolishness – yet it was also associated with the Virgin Mary, who was often shown standing on the full moon, a symbol of the Immaculate Conception.\n\nLunar imagery was equally prevalent in non-Christian traditions, with Sufi mystics using the Moon to represent Allah; for the Andalusian poet Ibn ‘Arabī (1165-1240), his divine beloved was ‘majestic, a full Moon risen within me, a Moon that never sets’. Mīrābāī (1500-46), an Indian princess who left her husband to devote herself to Krishna, expressed her devotion to this Hindu god in similarly evocative terms. Life without him would, she claimed, be like ‘a night without the Moon’; in other verses she compared herself to a lotus flower opening in the moonlight, and a bird enraptured at the sign of the Moon.\n\nThis influence was clearest in relation to human health, both physical and mental: the mad were widely described as ‘lunatic, that is mad at certain times of the moon’, and some authorities even suggested that a lunar eclipse in March 1345 was to blame for the Black Death. Consequently, physicians consulted lunar tables before preparing drugs or administering treatments; in Baghdad, the physician Bukhtíshū ibn Jibríl (d. 870) would only administer enemas when the Moon was descending. Six centuries later, the English surgeon John of Arderne (a skilful and forward-thinking practitioner, who also advocated for anaesthesia, pain relief, and clean hands) recommended that ‘a surgeon ought not cut or burn any member of a person’s body, nor do phlebotomy, while the Moon is in a sign governing or betokening that member’.\n\nOf course, a cynic might suggest that there was a more straightforward explanation for the thief’s good luck. Medieval literature was full of shenanigans on moonless nights, and of sinners thwarted by an unusually bright moon – as in Dafydd ap Gwilym’s poem Y lleuad (‘The Moon’), in which a man curses the Moon because its bright light thwarts his plan to visit his mistress. Such literary japes remind the modern reader how much things have changed. In our highly electrified world, we are no longer dependent on the Moon as a source of light. And yet, reading this sensitive study, it is hard not to feel a deep sense of connection with those long-ago skygazers. This celestial sphere has lost none of its mystery and allure.",
      "author": null,
      "published_date": null,
      "meta_description": "Across the medieval world, the Moon induced feelings of fear and fascination.",
      "word_count": 1070,
      "scraping_method": "goose3"
    },
    {
      "url": "https://totenarctanz.itch.io/a-scavenging-trip",
      "title": "Show HN: A PSX/DOS style 3D game written in Rust with a custom software renderer",
      "content": "A Scavenging Trip is a short and challenging simulation game were you are tasked with visiting an unknown planet, collect samples from its surface and leave in time. There are 3 missions with 3 difficulty levels each.\n\nA perfect speedrun through all difficulties should take around 10-15 minutes. A first playthrough might take 1-2 hours, especially because of the hardest difficulty.\n\nThere is not a Save feature, as all missions are unlocked and there is not any kind of progression whatsoever (although the order of the missions puts them into context).\n\nThe game uses minimal controls, which are rebindable through the Controls menu. Default scheme is WASDQE. Gamepads are currently not supported. The mouse is not used, so it's equivalently playable on a desktop or a laptop.\n\nThe system requirements are very low; if you are able to open this web page on a modern browser then most probably you can run the game at >30 fps. Any GPU from the last 25 years should do. It's recommended to have a Pentium M or better processor.\n\nMore exotic builds are possible for OSes supported by SDL2 and a relatively recent version of the Rust compiler (for example BSDs, Windows 7).\n\nSome more technical info for the curious\n\nThe game is developed using a custom software renderer and custom engine written in the Rust programming language. \"Software\" rendering in this context means that all graphics-related calculations are done by the CPU. The GPU is used only to present the final image to the display (and scale it depending on the window size).",
      "author": null,
      "published_date": null,
      "meta_description": "A short simulation adventure about scavenging an unknown planet",
      "word_count": 261,
      "scraping_method": "goose3"
    }
  ],
  "audio_files": [],
  "stats": {
    "stories_fetched": 20,
    "articles_scraped": 18,
    "total_words": 27631,
    "audio_files_generated": 0
  }
}